#!/usr/bin/env python3
"""
Neo4j ê¸°ë°˜ LangGraph RAG ì‹œìŠ¤í…œ

ê¸°ëŠ¥:
- ì„ë² ë”© ê¸°ë°˜ ìœ ì‚¬ë„ ê²€ìƒ‰
- ê·¸ë˜í”„ ê´€ê³„ë¥¼ í™œìš©í•œ í™•ì¥ ê²€ìƒ‰ 
- ì»¨í…ìŠ¤íŠ¸ ì •ë³´ í’ë¶€í™”
- ë‹¤ì¤‘ ê²€ìƒ‰ ì „ëµ ì§€ì›

ì‚¬ìš©ë²•:
    python scripts/neo4j_rag_system.py
"""

import os
from typing import List, Dict, Any, Optional, Tuple
from dataclasses import dataclass
from langchain_neo4j import Neo4jVector, Neo4jGraph
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_core.prompts import PromptTemplate
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser
from dotenv import load_dotenv

load_dotenv()

@dataclass
class SearchResult:
    """ê²€ìƒ‰ ê²°ê³¼ ë°ì´í„° í´ë˜ìŠ¤"""
    content: str
    concept_name: str
    node_type: str
    score: float
    metadata: Dict[str, Any]
    related_concepts: List[str] = None

class Neo4jLangGraphRAG:
    def __init__(self, neo4j_uri: str, neo4j_username: str, neo4j_password: str):
        self.graph = Neo4jGraph(
            url=neo4j_uri,
            username=neo4j_username,
            password=neo4j_password
        )
        self.embeddings = OpenAIEmbeddings(model="text-embedding-3-small")
        self.llm = ChatOpenAI(model="gpt-4.1-mini", temperature=0)
        
        # Neo4j Vector Store ì´ˆê¸°í™”
        self.setup_vector_stores()
        
        # RAG ì²´ì¸ ì„¤ì •
        self.setup_rag_chain()
    
    def setup_vector_stores(self):
        """ë²¡í„° ìŠ¤í† ì–´ ì„¤ì •"""
        print("ğŸ”§ ë²¡í„° ìŠ¤í† ì–´ ì„¤ì • ì¤‘...")
        
        # ê°œë… ë…¸ë“œìš© ë²¡í„° ìŠ¤í† ì–´
        self.concept_vector_store = Neo4jVector.from_existing_index(
            embedding=self.embeddings,
            url=os.getenv("NEO4J_URI"),
            username=os.getenv("NEO4J_USERNAME"),
            password=os.getenv("NEO4J_PASSWORD"),
            index_name="concept_embedding_index",
            node_label="Concept",
            text_node_property="definition",
            embedding_node_property="embedding",
            retrieval_query="""
            RETURN node.definition + ' ' + apoc.text.join(node.characteristics, ' ') + ' ' + node.usage AS text,
                   score,
                   {
                       name: node.name,
                       node_type: node.node_type,
                       characteristics: node.characteristics,
                       usage: node.usage,
                       source_file: node.source_file,
                       chunk_id: node.chunk_id
                   } AS metadata
            """
        )
        
        # ì²­í¬ìš© ë²¡í„° ìŠ¤í† ì–´ (í•˜ìœ„ ì„¹ì…˜ë“¤)
        self.chunk_vector_store = Neo4jVector.from_existing_index(
            embedding=self.embeddings,
            url=os.getenv("NEO4J_URI"),
            username=os.getenv("NEO4J_USERNAME"),
            password=os.getenv("NEO4J_PASSWORD"),
            index_name="chunk_embedding_index",
            node_label="Chunk",
            text_node_property="content",
            embedding_node_property="embedding",
            retrieval_query="""
            RETURN node.content AS text,
                   score,
                   {
                       title: node.title,
                       parent_concept: node.parent_concept,
                       chunk_type: node.chunk_type,
                       source_file: node.source_file,
                       chunk_id: node.chunk_id
                   } AS metadata
            """
        )
        
        print("âœ… ë²¡í„° ìŠ¤í† ì–´ ì„¤ì • ì™„ë£Œ")
    
    def setup_rag_chain(self):
        """RAG ì²´ì¸ ì„¤ì •"""
        template = """
ë‹¹ì‹ ì€ LangGraph ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì œê³µëœ ì§€ì‹ì„ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ì •í™•í•˜ê³  êµ¬ì²´ì ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”.

**ì§€ì‹ ë² ì´ìŠ¤:**
{context}

**ì§ˆë¬¸:** {question}

**ë‹µë³€ ì§€ì¹¨:**
1. ì œê³µëœ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì •í™•í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”
2. ê´€ë ¨ëœ ê°œë…ë“¤ê³¼ì˜ ê´€ê³„ë¥¼ ì„¤ëª…í•˜ì„¸ìš”  
3. ê°€ëŠ¥í•˜ë©´ êµ¬ì²´ì ì¸ ì˜ˆì‹œë‚˜ ì½”ë“œë¥¼ í¬í•¨í•˜ì„¸ìš”
4. ì¶”ê°€ í•™ìŠµì´ í•„ìš”í•œ ì„ í–‰ ê°œë…ì´ ìˆë‹¤ë©´ ì–¸ê¸‰í•˜ì„¸ìš”

**ë‹µë³€:**
"""
        
        self.prompt = PromptTemplate(
            template=template,
            input_variables=["context", "question"]
        )
    
    def enhanced_search(self, query: str, k: int = 5) -> List[SearchResult]:
        """í™•ì¥ ê²€ìƒ‰: ì„ë² ë”© + ê·¸ë˜í”„ ê´€ê³„ í™œìš©"""
        print(f"ğŸ” í™•ì¥ ê²€ìƒ‰ ì‹œì‘: '{query}'")
        
        # 1. ì„ë² ë”© ê¸°ë°˜ ì´ˆê¸° ê²€ìƒ‰
        concept_results = self.concept_vector_store.similarity_search_with_score(query, k=k)
        chunk_results = self.chunk_vector_store.similarity_search_with_score(query, k=k//2)
        
        # 2. ê²€ìƒ‰ ê²°ê³¼ í†µí•©
        all_results = []
        
        # ê°œë… ê²°ê³¼ ì²˜ë¦¬
        for doc, score in concept_results:
            result = SearchResult(
                content=f"**{doc.metadata['name']}**\nì •ì˜: {doc.page_content}\níŠ¹ì§•: {', '.join(doc.metadata.get('characteristics', []))}\ní™œìš©: {doc.metadata.get('usage', '')}",
                concept_name=doc.metadata['name'],
                node_type=doc.metadata.get('node_type', 'concept'),
                score=score,
                metadata=doc.metadata
            )
            all_results.append(result)
        
        # ì²­í¬ ê²°ê³¼ ì²˜ë¦¬
        for doc, score in chunk_results:
            result = SearchResult(
                content=f"**{doc.metadata['title']}** ({doc.metadata['parent_concept']})\n{doc.page_content}",
                concept_name=doc.metadata['parent_concept'],
                node_type="chunk",
                score=score,
                metadata=doc.metadata
            )
            all_results.append(result)
        
        # 3. ê´€ë ¨ ê°œë… í™•ì¥ ê²€ìƒ‰
        expanded_results = self.expand_with_relationships(all_results)
        
        print(f"   ğŸ“Š ì´ˆê¸° ê²°ê³¼: {len(all_results)}ê°œ, í™•ì¥ í›„: {len(expanded_results)}ê°œ")
        
        return expanded_results[:k*2]  # í™•ì¥ëœ ê²°ê³¼ì—ì„œ ìƒìœ„ ì„ íƒ
    
    def expand_with_relationships(self, initial_results: List[SearchResult]) -> List[SearchResult]:
        """ê´€ê³„ë¥¼ í™œìš©í•œ ê²€ìƒ‰ ê²°ê³¼ í™•ì¥"""
        expanded_results = initial_results.copy()
        
        for result in initial_results:
            if result.node_type == "chunk":
                continue  # ì²­í¬ëŠ” í™•ì¥í•˜ì§€ ì•ŠìŒ
                
            concept_name = result.concept_name
            
            # ê´€ë ¨ ê°œë…ë“¤ ê²€ìƒ‰
            related_query = """
            MATCH (c {name: $concept_name})
            MATCH (c)-[r]-(related)
            WHERE related:Concept OR related:Tutorial OR related:Pattern OR related:Tool
            RETURN related.name AS name, 
                   related.definition AS definition,
                   related.node_type AS node_type,
                   type(r) AS relationship_type,
                   related.characteristics AS characteristics,
                   related.usage AS usage
            LIMIT 3
            """
            
            try:
                related_concepts = self.graph.query(
                    related_query, 
                    params={"concept_name": concept_name}
                )
                
                result.related_concepts = []
                
                for related in related_concepts:
                    if related['name'] != concept_name:  # ìê¸° ìì‹  ì œì™¸
                        related_result = SearchResult(
                            content=f"**{related['name']}** (ê´€ë ¨: {related['relationship_type']})\nì •ì˜: {related['definition']}\ní™œìš©: {related.get('usage', '')}",
                            concept_name=related['name'],
                            node_type=related['node_type'],
                            score=result.score * 0.8,  # ê´€ë ¨ ê°œë…ì€ ì ìˆ˜ ê°ì†Œ
                            metadata={
                                'name': related['name'],
                                'node_type': related['node_type'],
                                'relationship_type': related['relationship_type'],
                                'characteristics': related.get('characteristics', []),
                                'usage': related.get('usage', '')
                            }
                        )
                        expanded_results.append(related_result)
                        result.related_concepts.append(related['name'])
                        
            except Exception as e:
                print(f"âš ï¸ ê´€ê³„ í™•ì¥ ì¤‘ ì—ëŸ¬ ({concept_name}): {e}")
        
        return expanded_results
    
    def get_learning_path(self, concept_name: str) -> Dict[str, List[str]]:
        """í•™ìŠµ ê²½ë¡œ ì¶”ì²œ"""
        path_query = """
        MATCH (target {name: $concept_name})
        
        // ì„ í–‰ ê°œë…ë“¤ (ë°°ì›Œì•¼ í•  ê²ƒë“¤)
        OPTIONAL MATCH (prereq)-[:PREREQUISITE]->(target)
        
        // í›„ì† ê°œë…ë“¤ (ë‹¤ìŒì— ë°°ìš¸ ê²ƒë“¤)  
        OPTIONAL MATCH (target)-[:PREREQUISITE]->(next)
        
        // ê´€ë ¨ ê°œë…ë“¤
        OPTIONAL MATCH (target)-[:RELATES_TO]-(related)
        
        RETURN 
            collect(DISTINCT prereq.name) AS prerequisites,
            collect(DISTINCT next.name) AS next_concepts,
            collect(DISTINCT related.name) AS related_concepts
        """
        
        try:
            result = self.graph.query(path_query, params={"concept_name": concept_name})
            if result:
                return {
                    "prerequisites": [name for name in result[0]['prerequisites'] if name],
                    "next_concepts": [name for name in result[0]['next_concepts'] if name], 
                    "related_concepts": [name for name in result[0]['related_concepts'] if name]
                }
        except Exception as e:
            print(f"âš ï¸ í•™ìŠµ ê²½ë¡œ ì¡°íšŒ ì—ëŸ¬: {e}")
        
        return {"prerequisites": [], "next_concepts": [], "related_concepts": []}
    
    def format_context(self, search_results: List[SearchResult]) -> str:
        """ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì»¨í…ìŠ¤íŠ¸ë¡œ í¬ë§·íŒ…"""
        context_parts = []
        
        # ì ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
        sorted_results = sorted(search_results, key=lambda x: x.score, reverse=True)
        
        for i, result in enumerate(sorted_results, 1):
            context_part = f"[ì •ë³´ {i}] {result.content}"
            
            # ê´€ë ¨ ê°œë… ì •ë³´ ì¶”ê°€
            if result.related_concepts:
                context_part += f"\nê´€ë ¨ ê°œë…: {', '.join(result.related_concepts)}"
            
            context_parts.append(context_part)
        
        return "\n\n".join(context_parts)
    
    def ask(self, question: str, search_strategy: str = "enhanced") -> Dict[str, Any]:
        """ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ ìƒì„±"""
        print(f"â“ ì§ˆë¬¸: {question}")
        
        # ê²€ìƒ‰ ì „ëµ ì„ íƒ
        if search_strategy == "enhanced":
            search_results = self.enhanced_search(question)
        elif search_strategy == "concept_only":
            concept_results = self.concept_vector_store.similarity_search_with_score(question, k=5)
            search_results = [
                SearchResult(
                    content=doc.page_content,
                    concept_name=doc.metadata['name'],
                    node_type=doc.metadata.get('node_type', 'concept'),
                    score=score,
                    metadata=doc.metadata
                ) for doc, score in concept_results
            ]
        else:
            search_results = self.enhanced_search(question)
        
        # ì»¨í…ìŠ¤íŠ¸ ìƒì„±
        context = self.format_context(search_results)
        
        # LLMìœ¼ë¡œ ë‹µë³€ ìƒì„±
        chain = (
            {"context": lambda x: context, "question": RunnablePassthrough()}
            | self.prompt
            | self.llm  
            | StrOutputParser()
        )
        
        answer = chain.invoke(question)
        
        # ì£¼ìš” ê°œë…ì˜ í•™ìŠµ ê²½ë¡œ ì¶”ê°€
        learning_paths = {}
        for result in search_results[:3]:  # ìƒìœ„ 3ê°œ ê°œë…ë§Œ
            if result.node_type in ["concept", "tutorial", "pattern"]:
                learning_paths[result.concept_name] = self.get_learning_path(result.concept_name)
        
        return {
            "answer": answer,
            "search_results": search_results,
            "learning_paths": learning_paths,
            "context_used": context
        }
    
    def get_concept_overview(self, concept_name: str) -> Dict[str, Any]:
        """íŠ¹ì • ê°œë…ì˜ ìƒì„¸ ì •ë³´"""
        overview_query = """
        MATCH (c {name: $concept_name})
        OPTIONAL MATCH (c)-[:HAS_SUBSECTION]->(sub:Chunk)
        RETURN c.name AS name,
               c.definition AS definition, 
               c.characteristics AS characteristics,
               c.usage AS usage,
               c.code_examples AS code_examples,
               c.node_type AS node_type,
               collect(sub.title) AS subsections
        """
        
        try:
            result = self.graph.query(overview_query, params={"concept_name": concept_name})
            if result:
                concept_data = result[0]
                learning_path = self.get_learning_path(concept_name)
                
                return {
                    "concept_info": concept_data,
                    "learning_path": learning_path
                }
        except Exception as e:
            print(f"âš ï¸ ê°œë… ì¡°íšŒ ì—ëŸ¬: {e}")
        
        return None
    
    def interactive_chat(self):
        """ëŒ€í™”í˜• ì¸í„°í˜ì´ìŠ¤"""
        print("ğŸ¤– LangGraph RAG ì‹œìŠ¤í…œì— ì˜¤ì‹  ê²ƒì„ í™˜ì˜í•©ë‹ˆë‹¤!")
        print("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš” (ì¢…ë£Œ: 'quit' ë˜ëŠ” 'exit')")
        print("-" * 50)
        
        while True:
            try:
                question = input("\nâ“ ì§ˆë¬¸: ").strip()
                
                if question.lower() in ['quit', 'exit', 'ì¢…ë£Œ']:
                    print("ğŸ‘‹ ê°ì‚¬í•©ë‹ˆë‹¤!")
                    break
                
                if not question:
                    continue
                
                # íŠ¹ë³„ ëª…ë ¹ì–´ ì²˜ë¦¬
                if question.startswith("/ê°œë… "):
                    concept_name = question[3:].strip()
                    overview = self.get_concept_overview(concept_name)
                    if overview:
                        info = overview["concept_info"]
                        print(f"\nğŸ“– **{info['name']}** ({info['node_type']})")
                        print(f"ì •ì˜: {info['definition']}")
                        if info['characteristics']:
                            print(f"íŠ¹ì§•: {', '.join(info['characteristics'])}")
                        print(f"í™œìš©: {info['usage']}")
                        
                        # í•™ìŠµ ê²½ë¡œ
                        path = overview["learning_path"]
                        if path['prerequisites']:
                            print(f"ì„ í–‰ ê°œë…: {', '.join(path['prerequisites'])}")
                        if path['next_concepts']:
                            print(f"í›„ì† ê°œë…: {', '.join(path['next_concepts'])}")
                    else:
                        print(f"âŒ '{concept_name}' ê°œë…ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    continue
                
                # ì¼ë°˜ ì§ˆë¬¸ ì²˜ë¦¬
                result = self.ask(question)
                
                print(f"\nğŸ’¡ **ë‹µë³€:**")
                print(result["answer"])
                
                print(f"\nğŸ“Š **ì°¸ê³ ëœ ê°œë…ë“¤:**")
                for i, search_result in enumerate(result["search_results"][:3], 1):
                    print(f"{i}. {search_result.concept_name} (ì ìˆ˜: {search_result.score:.3f})")
                
                # í•™ìŠµ ê²½ë¡œ ì œì•ˆ
                if result["learning_paths"]:
                    print(f"\nğŸ¯ **ì¶”ì²œ í•™ìŠµ ê²½ë¡œ:**")
                    for concept, path in result["learning_paths"].items():
                        if path['prerequisites']:
                            print(f"â€¢ {concept} í•™ìŠµ ì „ í•„ìš”: {', '.join(path['prerequisites'])}")
                
            except KeyboardInterrupt:
                print("\nğŸ‘‹ ê°ì‚¬í•©ë‹ˆë‹¤!")
                break
            except Exception as e:
                print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    # Neo4j ì—°ê²° ì •ë³´ í™•ì¸
    neo4j_uri = os.getenv("NEO4J_URI")
    neo4j_username = os.getenv("NEO4J_USERNAME")
    neo4j_password = os.getenv("NEO4J_PASSWORD")
    
    if not all([neo4j_uri, neo4j_username, neo4j_password]):
        print("âŒ Neo4j ì—°ê²° ì •ë³´ê°€ í•„ìš”í•©ë‹ˆë‹¤ (.env íŒŒì¼ í™•ì¸)")
        return
    
    try:
        # RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        print("ğŸš€ Neo4j LangGraph RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...")
        rag_system = Neo4jLangGraphRAG(neo4j_uri, neo4j_username, neo4j_password)
        
        # ëŒ€í™”í˜• ëª¨ë“œ ì‹œì‘
        rag_system.interactive_chat()
        
    except Exception as e:
        print(f"âŒ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")

if __name__ == "__main__":
    main() 