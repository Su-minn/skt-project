#!/usr/bin/env python3
"""
Neo4j Í∏∞Î∞ò LangGraph RAG ÏãúÏä§ÌÖú

Í∏∞Îä•:
- ÏûÑÎ≤†Îî© Í∏∞Î∞ò Ïú†ÏÇ¨ÎèÑ Í≤ÄÏÉâ
- Í∑∏ÎûòÌîÑ Í¥ÄÍ≥ÑÎ•º ÌôúÏö©Ìïú ÌôïÏû• Í≤ÄÏÉâ 
- Ïª®ÌÖçÏä§Ìä∏ Ï†ïÎ≥¥ ÌíçÎ∂ÄÌôî
- Îã§Ï§ë Í≤ÄÏÉâ Ï†ÑÎûµ ÏßÄÏõê

ÏÇ¨Ïö©Î≤ï:
    python scripts/neo4j_rag_system.py
"""

import os
from typing import List, Dict, Any, Optional, Tuple
from dataclasses import dataclass
from langchain_neo4j import Neo4jVector, Neo4jGraph
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_core.prompts import PromptTemplate
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser
from dotenv import load_dotenv

load_dotenv()

@dataclass
class SearchResult:
    """Í≤ÄÏÉâ Í≤∞Í≥º Îç∞Ïù¥ÌÑ∞ ÌÅ¥ÎûòÏä§"""
    content: str
    concept_name: str
    node_type: str
    score: float
    metadata: Dict[str, Any]
    related_concepts: List[str] = None

class Neo4jLangGraphRAG:
    def __init__(self, neo4j_uri: str, neo4j_username: str, neo4j_password: str):
        self.graph = Neo4jGraph(
            url=neo4j_uri,
            username=neo4j_username,
            password=neo4j_password
        )
        self.embeddings = OpenAIEmbeddings(model="text-embedding-3-small")
        self.llm = ChatOpenAI(model="gpt-4.1-mini", temperature=0)
        
        # Neo4j Vector Store Ï¥àÍ∏∞Ìôî
        self.setup_vector_stores()
        
        # RAG Ï≤¥Ïù∏ ÏÑ§Ï†ï
        self.setup_rag_chain()
    
    def setup_vector_stores(self):
        """Î≤°ÌÑ∞ Ïä§ÌÜ†Ïñ¥ ÏÑ§Ï†ï"""
        print("üîß Î≤°ÌÑ∞ Ïä§ÌÜ†Ïñ¥ ÏÑ§Ï†ï Ï§ë...")
        
        # Í∞úÎÖê ÎÖ∏ÎìúÏö© Î≤°ÌÑ∞ Ïä§ÌÜ†Ïñ¥
        self.concept_vector_store = Neo4jVector.from_existing_index(
            embedding=self.embeddings,
            url=os.getenv("NEO4J_URI"),
            username=os.getenv("NEO4J_USERNAME"),
            password=os.getenv("NEO4J_PASSWORD"),
            index_name="concept_embedding_index",
            node_label="Concept",
            text_node_property="definition",
            embedding_node_property="embedding",
            retrieval_query="""
            RETURN node.definition + ' ' + apoc.text.join(node.characteristics, ' ') + ' ' + node.usage AS text,
                   score,
                   {
                       name: node.name,
                       node_type: node.node_type,
                       characteristics: node.characteristics,
                       usage: node.usage,
                       source_file: node.source_file,
                       chunk_id: node.chunk_id
                   } AS metadata
            """
        )
        
        # Ï≤≠ÌÅ¨Ïö© Î≤°ÌÑ∞ Ïä§ÌÜ†Ïñ¥ (ÌïòÏúÑ ÏÑπÏÖòÎì§)
        self.chunk_vector_store = Neo4jVector.from_existing_index(
            embedding=self.embeddings,
            url=os.getenv("NEO4J_URI"),
            username=os.getenv("NEO4J_USERNAME"),
            password=os.getenv("NEO4J_PASSWORD"),
            index_name="chunk_embedding_index",
            node_label="Chunk",
            text_node_property="content",
            embedding_node_property="embedding",
            retrieval_query="""
            RETURN node.content AS text,
                   score,
                   {
                       title: node.title,
                       parent_concept: node.parent_concept,
                       chunk_type: node.chunk_type,
                       source_file: node.source_file,
                       chunk_id: node.chunk_id
                   } AS metadata
            """
        )
        
        print("‚úÖ Î≤°ÌÑ∞ Ïä§ÌÜ†Ïñ¥ ÏÑ§Ï†ï ÏôÑÎ£å")
    
    def setup_rag_chain(self):
        """RAG Ï≤¥Ïù∏ ÏÑ§Ï†ï"""
        template = """
ÎãπÏã†ÏùÄ LangGraph Ï†ÑÎ¨∏Í∞ÄÏûÖÎãàÎã§. Ï†úÍ≥µÎêú ÏßÄÏãùÏùÑ Î∞îÌÉïÏúºÎ°ú ÏßàÎ¨∏Ïóê Ï†ïÌôïÌïòÍ≥† Íµ¨Ï≤¥Ï†ÅÏúºÎ°ú ÎãµÎ≥ÄÌï¥Ï£ºÏÑ∏Ïöî.

**ÏßÄÏãù Î≤†Ïù¥Ïä§:**
{context}

**ÏßàÎ¨∏:** {question}

**ÎãµÎ≥Ä ÏßÄÏπ®:**
1. Ï†úÍ≥µÎêú Ï†ïÎ≥¥Î•º Î∞îÌÉïÏúºÎ°ú Ï†ïÌôïÌïòÍ≤å ÎãµÎ≥ÄÌïòÏÑ∏Ïöî
2. Í¥ÄÎ†®Îêú Í∞úÎÖêÎì§Í≥ºÏùò Í¥ÄÍ≥ÑÎ•º ÏÑ§Î™ÖÌïòÏÑ∏Ïöî  
3. Í∞ÄÎä•ÌïòÎ©¥ Íµ¨Ï≤¥Ï†ÅÏù∏ ÏòàÏãúÎÇò ÏΩîÎìúÎ•º Ìè¨Ìï®ÌïòÏÑ∏Ïöî
4. Ï∂îÍ∞Ä ÌïôÏäµÏù¥ ÌïÑÏöîÌïú ÏÑ†Ìñâ Í∞úÎÖêÏù¥ ÏûàÎã§Î©¥ Ïñ∏Í∏âÌïòÏÑ∏Ïöî

**ÎãµÎ≥Ä:**
"""
        
        self.prompt = PromptTemplate(
            template=template,
            input_variables=["context", "question"]
        )
    
    def enhanced_search(self, query: str, k: int = 5) -> List[SearchResult]:
        """ÌôïÏû• Í≤ÄÏÉâ: ÏûÑÎ≤†Îî© + Í∑∏ÎûòÌîÑ Í¥ÄÍ≥Ñ ÌôúÏö©"""
        print(f"üîç ÌôïÏû• Í≤ÄÏÉâ ÏãúÏûë: '{query}'")
        
        # 1. ÏûÑÎ≤†Îî© Í∏∞Î∞ò Ï¥àÍ∏∞ Í≤ÄÏÉâ
        concept_results = self.concept_vector_store.similarity_search_with_score(query, k=k)
        chunk_results = self.chunk_vector_store.similarity_search_with_score(query, k=k//2)
        
        # 2. Í≤ÄÏÉâ Í≤∞Í≥º ÌÜµÌï©
        all_results = []
        
        # Í∞úÎÖê Í≤∞Í≥º Ï≤òÎ¶¨
        for doc, score in concept_results:
            result = SearchResult(
                content=f"**{doc.metadata['name']}**\nÏ†ïÏùò: {doc.page_content}\nÌäπÏßï: {', '.join(doc.metadata.get('characteristics', []))}\nÌôúÏö©: {doc.metadata.get('usage', '')}",
                concept_name=doc.metadata['name'],
                node_type=doc.metadata.get('node_type', 'concept'),
                score=score,
                metadata=doc.metadata
            )
            all_results.append(result)
        
        # Ï≤≠ÌÅ¨ Í≤∞Í≥º Ï≤òÎ¶¨
        for doc, score in chunk_results:
            result = SearchResult(
                content=f"**{doc.metadata['title']}** ({doc.metadata['parent_concept']})\n{doc.page_content}",
                concept_name=doc.metadata['parent_concept'],
                node_type="chunk",
                score=score,
                metadata=doc.metadata
            )
            all_results.append(result)
        
        # 3. Í¥ÄÎ†® Í∞úÎÖê ÌôïÏû• Í≤ÄÏÉâ
        expanded_results = self.expand_with_relationships(all_results)
        
        print(f"   üìä Ï¥àÍ∏∞ Í≤∞Í≥º: {len(all_results)}Í∞ú, ÌôïÏû• ÌõÑ: {len(expanded_results)}Í∞ú")
        
        return expanded_results[:k*2]  # ÌôïÏû•Îêú Í≤∞Í≥ºÏóêÏÑú ÏÉÅÏúÑ ÏÑ†ÌÉù
    
    def expand_with_relationships(self, initial_results: List[SearchResult]) -> List[SearchResult]:
        """Í¥ÄÍ≥ÑÎ•º ÌôúÏö©Ìïú Í≤ÄÏÉâ Í≤∞Í≥º ÌôïÏû•"""
        expanded_results = initial_results.copy()
        
        for result in initial_results:
            if result.node_type == "chunk":
                continue  # Ï≤≠ÌÅ¨Îäî ÌôïÏû•ÌïòÏßÄ ÏïäÏùå
                
            concept_name = result.concept_name
            
            # Í¥ÄÎ†® Í∞úÎÖêÎì§ Í≤ÄÏÉâ
            related_query = """
            MATCH (c {name: $concept_name})
            MATCH (c)-[r]-(related)
            WHERE related:Concept OR related:Tutorial OR related:Pattern OR related:Tool
            RETURN related.name AS name, 
                   related.definition AS definition,
                   related.node_type AS node_type,
                   type(r) AS relationship_type,
                   related.characteristics AS characteristics,
                   related.usage AS usage
            LIMIT 3
            """
            
            try:
                related_concepts = self.graph.query(
                    related_query, 
                    params={"concept_name": concept_name}
                )
                
                result.related_concepts = []
                
                for related in related_concepts:
                    if related['name'] != concept_name:  # ÏûêÍ∏∞ ÏûêÏã† Ï†úÏô∏
                        related_result = SearchResult(
                            content=f"**{related['name']}** (Í¥ÄÎ†®: {related['relationship_type']})\nÏ†ïÏùò: {related['definition']}\nÌôúÏö©: {related.get('usage', '')}",
                            concept_name=related['name'],
                            node_type=related['node_type'],
                            score=result.score * 0.8,  # Í¥ÄÎ†® Í∞úÎÖêÏùÄ Ï†êÏàò Í∞êÏÜå
                            metadata={
                                'name': related['name'],
                                'node_type': related['node_type'],
                                'relationship_type': related['relationship_type'],
                                'characteristics': related.get('characteristics', []),
                                'usage': related.get('usage', '')
                            }
                        )
                        expanded_results.append(related_result)
                        result.related_concepts.append(related['name'])
                        
            except Exception as e:
                print(f"‚ö†Ô∏è Í¥ÄÍ≥Ñ ÌôïÏû• Ï§ë ÏóêÎü¨ ({concept_name}): {e}")
        
        return expanded_results
    
    def get_learning_path(self, concept_name: str) -> Dict[str, List[str]]:
        """ÌïôÏäµ Í≤ΩÎ°ú Ï∂îÏ≤ú"""
        path_query = """
        MATCH (target {name: $concept_name})
        
        // ÏÑ†Ìñâ Í∞úÎÖêÎì§ (Î∞∞ÏõåÏïº Ìï† Í≤ÉÎì§)
        OPTIONAL MATCH (prereq)-[:PREREQUISITE]->(target)
        
        // ÌõÑÏÜç Í∞úÎÖêÎì§ (Îã§ÏùåÏóê Î∞∞Ïö∏ Í≤ÉÎì§)  
        OPTIONAL MATCH (target)-[:PREREQUISITE]->(next)
        
        // Í¥ÄÎ†® Í∞úÎÖêÎì§
        OPTIONAL MATCH (target)-[:RELATES_TO]-(related)
        
        RETURN 
            collect(DISTINCT prereq.name) AS prerequisites,
            collect(DISTINCT next.name) AS next_concepts,
            collect(DISTINCT related.name) AS related_concepts
        """
        
        try:
            result = self.graph.query(path_query, params={"concept_name": concept_name})
            if result:
                return {
                    "prerequisites": [name for name in result[0]['prerequisites'] if name],
                    "next_concepts": [name for name in result[0]['next_concepts'] if name], 
                    "related_concepts": [name for name in result[0]['related_concepts'] if name]
                }
        except Exception as e:
            print(f"‚ö†Ô∏è ÌïôÏäµ Í≤ΩÎ°ú Ï°∞Ìöå ÏóêÎü¨: {e}")
        
        return {"prerequisites": [], "next_concepts": [], "related_concepts": []}
    
    def format_context(self, search_results: List[SearchResult]) -> str:
        """Í≤ÄÏÉâ Í≤∞Í≥ºÎ•º Ïª®ÌÖçÏä§Ìä∏Î°ú Ìè¨Îß∑ÌåÖ"""
        context_parts = []
        
        # Ï†êÏàò Í∏∞Ï§ÄÏúºÎ°ú Ï†ïÎ†¨
        sorted_results = sorted(search_results, key=lambda x: x.score, reverse=True)
        
        for i, result in enumerate(sorted_results, 1):
            context_part = f"[Ï†ïÎ≥¥ {i}] {result.content}"
            
            # Í¥ÄÎ†® Í∞úÎÖê Ï†ïÎ≥¥ Ï∂îÍ∞Ä
            if result.related_concepts:
                context_part += f"\nÍ¥ÄÎ†® Í∞úÎÖê: {', '.join(result.related_concepts)}"
            
            context_parts.append(context_part)
        
        return "\n\n".join(context_parts)
    
    def ask(self, question: str, search_strategy: str = "enhanced") -> Dict[str, Any]:
        """ÏßàÎ¨∏Ïóê ÎåÄÌïú ÎãµÎ≥Ä ÏÉùÏÑ±"""
        print(f"‚ùì ÏßàÎ¨∏: {question}")
        
        # Í≤ÄÏÉâ Ï†ÑÎûµ ÏÑ†ÌÉù
        if search_strategy == "enhanced":
            search_results = self.enhanced_search(question)
        elif search_strategy == "concept_only":
            concept_results = self.concept_vector_store.similarity_search_with_score(question, k=5)
            search_results = [
                SearchResult(
                    content=doc.page_content,
                    concept_name=doc.metadata['name'],
                    node_type=doc.metadata.get('node_type', 'concept'),
                    score=score,
                    metadata=doc.metadata
                ) for doc, score in concept_results
            ]
        else:
            search_results = self.enhanced_search(question)
        
        # Ïª®ÌÖçÏä§Ìä∏ ÏÉùÏÑ±
        context = self.format_context(search_results)
        
        # LLMÏúºÎ°ú ÎãµÎ≥Ä ÏÉùÏÑ±
        chain = (
            {"context": lambda x: context, "question": RunnablePassthrough()}
            | self.prompt
            | self.llm  
            | StrOutputParser()
        )
        
        answer = chain.invoke(question)
        
        # Ï£ºÏöî Í∞úÎÖêÏùò ÌïôÏäµ Í≤ΩÎ°ú Ï∂îÍ∞Ä
        learning_paths = {}
        for result in search_results[:3]:  # ÏÉÅÏúÑ 3Í∞ú Í∞úÎÖêÎßå
            if result.node_type in ["concept", "tutorial", "pattern"]:
                learning_paths[result.concept_name] = self.get_learning_path(result.concept_name)
        
        return {
            "answer": answer,
            "search_results": search_results,
            "learning_paths": learning_paths,
            "context_used": context
        }
    
    def get_concept_overview(self, concept_name: str) -> Dict[str, Any]:
        """ÌäπÏ†ï Í∞úÎÖêÏùò ÏÉÅÏÑ∏ Ï†ïÎ≥¥"""
        overview_query = """
        MATCH (c {name: $concept_name})
        OPTIONAL MATCH (c)-[:HAS_SUBSECTION]->(sub:Chunk)
        RETURN c.name AS name,
               c.definition AS definition, 
               c.characteristics AS characteristics,
               c.usage AS usage,
               c.code_examples AS code_examples,
               c.node_type AS node_type,
               collect(sub.title) AS subsections
        """
        
        try:
            result = self.graph.query(overview_query, params={"concept_name": concept_name})
            if result:
                concept_data = result[0]
                learning_path = self.get_learning_path(concept_name)
                
                return {
                    "concept_info": concept_data,
                    "learning_path": learning_path
                }
        except Exception as e:
            print(f"‚ö†Ô∏è Í∞úÎÖê Ï°∞Ìöå ÏóêÎü¨: {e}")
        
        return None
    
    def interactive_chat(self):
        """ÎåÄÌôîÌòï Ïù∏ÌÑ∞ÌéòÏù¥Ïä§"""
        print("ü§ñ LangGraph RAG ÏãúÏä§ÌÖúÏóê Ïò§Ïã† Í≤ÉÏùÑ ÌôòÏòÅÌï©ÎãàÎã§!")
        print("ÏßàÎ¨∏ÏùÑ ÏûÖÎ†•ÌïòÏÑ∏Ïöî (Ï¢ÖÎ£å: 'quit' ÎòêÎäî 'exit')")
        print("-" * 50)
        
        while True:
            try:
                question = input("\n‚ùì ÏßàÎ¨∏: ").strip()
                
                if question.lower() in ['quit', 'exit', 'Ï¢ÖÎ£å']:
                    print("üëã Í∞êÏÇ¨Ìï©ÎãàÎã§!")
                    break
                
                if not question:
                    continue
                
                # ÌäπÎ≥Ñ Î™ÖÎ†πÏñ¥ Ï≤òÎ¶¨
                if question.startswith("/Í∞úÎÖê "):
                    concept_name = question[3:].strip()
                    overview = self.get_concept_overview(concept_name)
                    if overview:
                        info = overview["concept_info"]
                        print(f"\nüìñ **{info['name']}** ({info['node_type']})")
                        print(f"Ï†ïÏùò: {info['definition']}")
                        if info['characteristics']:
                            print(f"ÌäπÏßï: {', '.join(info['characteristics'])}")
                        print(f"ÌôúÏö©: {info['usage']}")
                        
                        # ÌïôÏäµ Í≤ΩÎ°ú
                        path = overview["learning_path"]
                        if path['prerequisites']:
                            print(f"ÏÑ†Ìñâ Í∞úÎÖê: {', '.join(path['prerequisites'])}")
                        if path['next_concepts']:
                            print(f"ÌõÑÏÜç Í∞úÎÖê: {', '.join(path['next_concepts'])}")
                    else:
                        print(f"‚ùå '{concept_name}' Í∞úÎÖêÏùÑ Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§.")
                    continue
                
                # ÏùºÎ∞ò ÏßàÎ¨∏ Ï≤òÎ¶¨
                result = self.ask(question)
                
                print(f"\nüí° **ÎãµÎ≥Ä:**")
                print(result["answer"])
                
                print(f"\nüìä **Ï∞∏Í≥†Îêú Í∞úÎÖêÎì§:**")
                for i, search_result in enumerate(result["search_results"][:3], 1):
                    print(f"{i}. {search_result.concept_name} (Ï†êÏàò: {search_result.score:.3f})")
                
                # ÌïôÏäµ Í≤ΩÎ°ú Ï†úÏïà
                if result["learning_paths"]:
                    print(f"\nüéØ **Ï∂îÏ≤ú ÌïôÏäµ Í≤ΩÎ°ú:**")
                    for concept, path in result["learning_paths"].items():
                        if path['prerequisites']:
                            print(f"‚Ä¢ {concept} ÌïôÏäµ Ï†Ñ ÌïÑÏöî: {', '.join(path['prerequisites'])}")
                
            except KeyboardInterrupt:
                print("\nüëã Í∞êÏÇ¨Ìï©ÎãàÎã§!")
                break
            except Exception as e:
                print(f"‚ùå Ïò§Î•ò Î∞úÏÉù: {e}")

def main():
    """Î©îÏù∏ Ïã§Ìñâ Ìï®Ïàò"""
    # Neo4j Ïó∞Í≤∞ Ï†ïÎ≥¥ ÌôïÏù∏
    neo4j_uri = os.getenv("NEO4J_URI")
    neo4j_username = os.getenv("NEO4J_USERNAME")
    neo4j_password = os.getenv("NEO4J_PASSWORD")
    
    if not all([neo4j_uri, neo4j_username, neo4j_password]):
        print("‚ùå Neo4j Ïó∞Í≤∞ Ï†ïÎ≥¥Í∞Ä ÌïÑÏöîÌï©ÎãàÎã§ (.env ÌååÏùº ÌôïÏù∏)")
        return
    
    try:
        # RAG ÏãúÏä§ÌÖú Ï¥àÍ∏∞Ìôî
        print("üöÄ Neo4j LangGraph RAG ÏãúÏä§ÌÖú Ï¥àÍ∏∞Ìôî Ï§ë...")
        rag_system = Neo4jLangGraphRAG(neo4j_uri, neo4j_username, neo4j_password)
        
        # ÎåÄÌôîÌòï Î™®Îìú ÏãúÏûë
        rag_system.interactive_chat()
        
    except Exception as e:
        print(f"‚ùå ÏãúÏä§ÌÖú Ï¥àÍ∏∞Ìôî Ïã§Ìå®: {e}")

if __name__ == "__main__":
    main() 