#!/usr/bin/env python3
"""
ë§ˆí¬ë‹¤ìš´ â†’ Neo4j íŒŒì‹± ë° ì €ì¥ ìŠ¤í¬ë¦½íŠ¸

ê¸°ëŠ¥:
- ì •ì œëœ ë§ˆí¬ë‹¤ìš´ì—ì„œ LangGraph ê°œë… ì¶”ì¶œ
- ê²¬ê³ í•œ íŒŒì‹±: êµ¬ì¡° ë³€í™”ì— ëŒ€ì‘í•˜ëŠ” ìœ ì—°í•œ ë¡œì§
- Neo4j ë…¸ë“œ/ê´€ê³„ ìƒì„± ë° ì„ë² ë”© ì €ì¥
- RAG ê²€ìƒ‰ì„ ìœ„í•œ ë©”íƒ€ë°ì´í„° êµ¬ì¡°í™”

ì‚¬ìš©ë²•:
    python scripts/markdown_to_neo4j_parser.py <input_file>
"""

import sys
import re
import uuid
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Any
from dataclasses import dataclass, field
from langchain_openai import OpenAIEmbeddings
from langchain_neo4j import Neo4jGraph
from dotenv import load_dotenv
import os

load_dotenv()

@dataclass
class ConceptNode:
    """LangGraph ê°œë… ë…¸ë“œ ë°ì´í„° í´ë˜ìŠ¤"""
    name: str
    node_type: str  # "concept", "tutorial", "pattern", "tool", "usecase"
    definition: str = ""
    characteristics: List[str] = field(default_factory=list)
    usage: str = ""
    code_examples: List[str] = field(default_factory=list)
    subsections: Dict[str, str] = field(default_factory=dict)
    source_file: str = ""
    section_order: int = 0
    chunk_id: str = field(default_factory=lambda: str(uuid.uuid4()))

@dataclass
class ConceptRelationship:
    """ê°œë… ê°„ ê´€ê³„ ë°ì´í„° í´ë˜ìŠ¤"""
    from_concept: str
    to_concept: str
    relationship_type: str  # "PREREQUISITE", "BUILDS_UPON", "IMPLEMENTS", "TEACHES", "SUPPORTS", "RELATES_TO"
    weight: float = 1.0

class MarkdownToNeo4jParser:
    def __init__(self, neo4j_uri: str, neo4j_username: str, neo4j_password: str):
        self.graph = Neo4jGraph(
            url=neo4j_uri,
            username=neo4j_username, 
            password=neo4j_password
        )
        self.embeddings = OpenAIEmbeddings(model="text-embedding-3-small")
        
        # íŒŒì‹± íŒ¨í„´ ì •ì˜
        self.concept_pattern = re.compile(r'^## (.+?)$', re.MULTILINE)
        self.definition_pattern = re.compile(r'\*\*ì •ì˜\*\*:\s*(.+?)(?=\n\n|\*\*|###|##|$)', re.DOTALL)
        self.characteristics_pattern = re.compile(r'\*\*íŠ¹ì§•\*\*:\s*\n\n((?:- .+?\n)+)', re.DOTALL)
        self.usage_pattern = re.compile(r'\*\*í™œìš©\*\*:\s*(.+?)(?=\n\n|\*\*|###|##|$)', re.DOTALL)
        self.code_block_pattern = re.compile(r'```[\w]*\n(.*?)\n```', re.DOTALL)
        
        # ê´€ê³„ íŒ¨í„´ë“¤ (ìœ ì—°í•œ ë§¤ì¹­)
        self.relationship_patterns = {
            'prerequisite': re.compile(r'\*\*ì„ í–‰ ê°œë…\*\*:\s*\[(.+?)\]', re.DOTALL),
            'related': re.compile(r'\*\*ì—°ê´€ ê°œë…\*\*:\s*\[(.+?)\]', re.DOTALL),
            'opposite': re.compile(r'\*\*ë°˜ëŒ€ ê°œë…\*\*:\s*\[(.+?)\]', re.DOTALL),
        }
    
    def setup_neo4j_schema(self):
        """Neo4j ìŠ¤í‚¤ë§ˆ ì„¤ì •"""
        print("ğŸ—ï¸ Neo4j ìŠ¤í‚¤ë§ˆ ì„¤ì • ì¤‘...")
        
        # ì œì•½ì¡°ê±´ ìƒì„±
        constraints = [
            "CREATE CONSTRAINT IF NOT EXISTS FOR (c:Concept) REQUIRE c.name IS UNIQUE",
            "CREATE CONSTRAINT IF NOT EXISTS FOR (t:Tutorial) REQUIRE t.title IS UNIQUE", 
            "CREATE CONSTRAINT IF NOT EXISTS FOR (p:Pattern) REQUIRE p.name IS UNIQUE",
            "CREATE CONSTRAINT IF NOT EXISTS FOR (ch:Chunk) REQUIRE ch.chunk_id IS UNIQUE"
        ]
        
        for constraint in constraints:
            self.graph.query(constraint)
        
        # ë²¡í„° ì¸ë±ìŠ¤ ìƒì„±
        vector_index = """
        CREATE VECTOR INDEX concept_embedding_index IF NOT EXISTS
        FOR (c:Concept) 
        ON (c.embedding)
        OPTIONS {
          indexConfig: {
            `vector.dimensions`: 1536,
            `vector.similarity_function`: 'cosine'
          }
        }
        """
        self.graph.query(vector_index)
        
        # ì¶”ê°€ ë²¡í„° ì¸ë±ìŠ¤ë“¤
        additional_indexes = [
            """
            CREATE VECTOR INDEX chunk_embedding_index IF NOT EXISTS
            FOR (ch:Chunk) 
            ON (ch.embedding)
            OPTIONS {
              indexConfig: {
                `vector.dimensions`: 1536,
                `vector.similarity_function`: 'cosine'
              }
            }
            """,
            """
            CREATE VECTOR INDEX tutorial_embedding_index IF NOT EXISTS
            FOR (t:Tutorial) 
            ON (t.embedding)
            OPTIONS {
              indexConfig: {
                `vector.dimensions`: 1536,
                `vector.similarity_function`: 'cosine'
              }
            }
            """
        ]
        
        for index in additional_indexes:
            self.graph.query(index)
        
        print("âœ… Neo4j ìŠ¤í‚¤ë§ˆ ì„¤ì • ì™„ë£Œ")
    
    def clean_text(self, text: str) -> str:
        """í…ìŠ¤íŠ¸ ì •ì œ"""
        if not text:
            return ""
        
        # ë¶ˆí•„ìš”í•œ ê³µë°±ê³¼ ì¤„ë°”ê¿ˆ ì œê±°
        text = re.sub(r'\n+', ' ', text)
        text = re.sub(r'\s+', ' ', text)
        return text.strip()
    
    def extract_concept_sections(self, content: str) -> List[Tuple[str, str]]:
        """ê°œë… ì„¹ì…˜ë“¤ì„ ì¶”ì¶œ"""
        sections = []
        concept_matches = list(self.concept_pattern.finditer(content))
        
        for i, match in enumerate(concept_matches):
            concept_name = match.group(1).strip()
            start_pos = match.end()
            
            # ë‹¤ìŒ ì„¹ì…˜ì˜ ì‹œì‘ ìœ„ì¹˜ ì°¾ê¸°
            if i + 1 < len(concept_matches):
                end_pos = concept_matches[i + 1].start()
            else:
                end_pos = len(content)
            
            section_content = content[start_pos:end_pos].strip()
            sections.append((concept_name, section_content))
        
        return sections
    
    def determine_node_type(self, concept_name: str, content: str) -> str:
        """ë…¸ë“œ íƒ€ì… ê²°ì •"""
        concept_lower = concept_name.lower()
        content_lower = content.lower()
        
        if '[ì‹¤ìŠµ]' in concept_name or 'tutorial' in concept_lower:
            return "tutorial"
        elif 'ì‹¤í–‰' in concept_name or 'stream' in concept_lower or 'invoke' in concept_lower:
            return "pattern"
        elif 'studio' in concept_lower or 'tool' in concept_lower:
            return "tool"
        elif 'vs.' in concept_name or 'ë¹„êµ' in concept_name:
            return "usecase"
        else:
            return "concept"
    
    def parse_concept_content(self, concept_name: str, content: str, source_file: str, section_order: int) -> ConceptNode:
        """ê°œë… ë‚´ìš© íŒŒì‹± (ê²¬ê³ í•œ ì—ëŸ¬ ì²˜ë¦¬)"""
        node_type = self.determine_node_type(concept_name, content)
        concept = ConceptNode(
            name=concept_name,
            node_type=node_type,
            source_file=source_file,
            section_order=section_order
        )
        
        try:
            # ì •ì˜ ì¶”ì¶œ
            def_match = self.definition_pattern.search(content)
            if def_match:
                concept.definition = self.clean_text(def_match.group(1))
            
            # íŠ¹ì§• ì¶”ì¶œ
            char_match = self.characteristics_pattern.search(content)
            if char_match:
                characteristics_text = char_match.group(1)
                characteristics = re.findall(r'- (.+?)(?=\n|$)', characteristics_text)
                concept.characteristics = [self.clean_text(c) for c in characteristics]
            
            # í™œìš© ì¶”ì¶œ
            usage_match = self.usage_pattern.search(content)
            if usage_match:
                concept.usage = self.clean_text(usage_match.group(1))
            
            # ì½”ë“œ ì˜ˆì œ ì¶”ì¶œ
            code_matches = self.code_block_pattern.findall(content)
            concept.code_examples = [code.strip() for code in code_matches if code.strip()]
            
            # í•˜ìœ„ ì„¹ì…˜ ì¶”ì¶œ
            subsection_pattern = re.compile(r'### (.+?)\n(.*?)(?=###|##|$)', re.DOTALL)
            subsection_matches = subsection_pattern.findall(content)
            for subsection_title, subsection_content in subsection_matches:
                concept.subsections[subsection_title.strip()] = self.clean_text(subsection_content)
        
        except Exception as e:
            print(f"âš ï¸ ê°œë… '{concept_name}' íŒŒì‹± ì¤‘ ì—ëŸ¬: {e}")
            # ì—ëŸ¬ê°€ ë°œìƒí•´ë„ ê¸°ë³¸ ì •ë³´ëŠ” ìœ ì§€
        
        return concept
    
    def extract_relationships(self, content: str) -> List[ConceptRelationship]:
        """ê´€ê³„ ì •ë³´ ì¶”ì¶œ (ìœ ì—°í•œ íŒ¨í„´ ë§¤ì¹­)"""
        relationships = []
        
        # ê´€ê³„ ì„¹ì…˜ ì°¾ê¸°
        relationship_section_pattern = re.compile(r'\*\*ê´€ê³„\*\*:\s*(.*?)(?=\n---|\n##|$)', re.DOTALL)
        rel_match = relationship_section_pattern.search(content)
        
        if not rel_match:
            return relationships
        
        relationship_content = rel_match.group(1)
        
        # ê° ê´€ê³„ íƒ€ì…ë³„ë¡œ ì¶”ì¶œ
        for rel_type, pattern in self.relationship_patterns.items():
            matches = pattern.findall(relationship_content)
            for match in matches:
                # ê°œë…ë“¤ì„ ë¶„ë¦¬ (ì‰¼í‘œ, ê´„í˜¸ ë“± ê³ ë ¤)
                concepts = re.split(r'[,ï¼Œ]|\s+', match)
                concepts = [self.clean_concept_name(c) for c in concepts if c.strip()]
                
                for concept in concepts:
                    if concept:
                        relationships.append(ConceptRelationship(
                            from_concept="",  # ë‚˜ì¤‘ì— ì„¤ì •
                            to_concept=concept,
                            relationship_type=self.map_relationship_type(rel_type)
                        ))
        
        return relationships
    
    def clean_concept_name(self, name: str) -> str:
        """ê°œë… ì´ë¦„ ì •ì œ"""
        # ëŒ€ê´„í˜¸, ê´„í˜¸ ì œê±°
        name = re.sub(r'[\[\]()]', '', name)
        # ë¶ˆí•„ìš”í•œ ê³µë°± ì œê±°
        name = name.strip()
        return name
    
    def map_relationship_type(self, rel_type: str) -> str:
        """ê´€ê³„ íƒ€ì… ë§¤í•‘"""
        mapping = {
            'prerequisite': 'PREREQUISITE',
            'related': 'RELATES_TO', 
            'opposite': 'OPPOSITE_OF'
        }
        return mapping.get(rel_type, 'RELATES_TO')
    
    def create_concept_node(self, concept: ConceptNode) -> str:
        """Neo4jì— ê°œë… ë…¸ë“œ ìƒì„±"""
        # ì„ë² ë”© ìƒì„± (ì •ì˜ + íŠ¹ì§• + í™œìš©)
        embedding_text = f"{concept.definition} {' '.join(concept.characteristics)} {concept.usage}"
        embedding = self.embeddings.embed_query(embedding_text)
        
        # ë…¸ë“œ ìƒì„± ì¿¼ë¦¬
        query = f"""
        MERGE (c:{concept.node_type.title()} {{name: $name}})
        SET c.definition = $definition,
            c.characteristics = $characteristics,
            c.usage = $usage,
            c.code_examples = $code_examples,
            c.source_file = $source_file,
            c.section_order = $section_order,
            c.chunk_id = $chunk_id,
            c.node_type = $node_type,
            c.created_at = datetime()
        WITH c
        CALL db.create.setNodeVectorProperty(c, 'embedding', $embedding)
        RETURN c.chunk_id as chunk_id
        """
        
        params = {
            "name": concept.name,
            "definition": concept.definition,
            "characteristics": concept.characteristics,
            "usage": concept.usage,
            "code_examples": concept.code_examples,
            "source_file": concept.source_file,
            "section_order": concept.section_order,
            "chunk_id": concept.chunk_id,
            "node_type": concept.node_type,
            "embedding": embedding
        }
        
        result = self.graph.query(query, params=params)
        return result[0]["chunk_id"] if result else concept.chunk_id
    
    def create_subsection_chunks(self, concept: ConceptNode):
        """í•˜ìœ„ ì„¹ì…˜ì„ ë³„ë„ ì²­í¬ë¡œ ìƒì„±"""
        for subsection_title, subsection_content in concept.subsections.items():
            if not subsection_content.strip():
                continue
                
            chunk_id = str(uuid.uuid4())
            embedding = self.embeddings.embed_query(subsection_content)
            
            query = """
            MATCH (c {name: $concept_name})
            CREATE (ch:Chunk {
                chunk_id: $chunk_id,
                title: $title,
                content: $content,
                parent_concept: $concept_name,
                source_file: $source_file,
                chunk_type: 'subsection',
                created_at: datetime()
            })
            WITH ch, c
            CALL db.create.setNodeVectorProperty(ch, 'embedding', $embedding)
            CREATE (c)-[:HAS_SUBSECTION]->(ch)
            RETURN ch.chunk_id
            """
            
            params = {
                "concept_name": concept.name,
                "chunk_id": chunk_id,
                "title": subsection_title,
                "content": subsection_content,
                "source_file": concept.source_file,
                "embedding": embedding
            }
            
            self.graph.query(query, params=params)
    
    def create_relationships(self, relationships: List[ConceptRelationship]):
        """ê´€ê³„ ìƒì„±"""
        for rel in relationships:
            if not rel.from_concept or not rel.to_concept:
                continue
                
            query = f"""
            MATCH (from {{name: $from_concept}})
            MATCH (to {{name: $to_concept}})
            MERGE (from)-[r:{rel.relationship_type}]->(to)
            SET r.weight = $weight,
                r.created_at = datetime()
            RETURN r
            """
            
            params = {
                "from_concept": rel.from_concept,
                "to_concept": rel.to_concept,
                "weight": rel.weight
            }
            
            try:
                self.graph.query(query, params=params)
            except Exception as e:
                print(f"âš ï¸ ê´€ê³„ ìƒì„± ì‹¤íŒ¨: {rel.from_concept} -> {rel.to_concept} ({e})")
    
    def parse_and_store(self, markdown_file: str):
        """ë§ˆí¬ë‹¤ìš´ íŒŒì¼ íŒŒì‹± ë° Neo4j ì €ì¥"""
        print(f"ğŸ“„ íŒŒì¼ íŒŒì‹± ì‹œì‘: {markdown_file}")
        
        # íŒŒì¼ ì½ê¸°
        with open(markdown_file, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # ê°œë… ì„¹ì…˜ ì¶”ì¶œ
        concept_sections = self.extract_concept_sections(content)
        print(f"ğŸ“Š ì¶”ì¶œëœ ê°œë… ì„¹ì…˜: {len(concept_sections)}ê°œ")
        
        # ìŠ¤í‚¤ë§ˆ ì„¤ì •
        self.setup_neo4j_schema()
        
        # ê°œë…ë“¤ê³¼ ê´€ê³„ë“¤ ì €ì¥
        all_relationships = []
        created_concepts = []
        
        for i, (concept_name, section_content) in enumerate(concept_sections):
            try:
                print(f"ğŸ”„ ì²˜ë¦¬ ì¤‘: {concept_name}")
                
                # ê°œë… íŒŒì‹±
                concept = self.parse_concept_content(
                    concept_name, 
                    section_content, 
                    Path(markdown_file).name, 
                    i
                )
                
                # ë…¸ë“œ ìƒì„±
                chunk_id = self.create_concept_node(concept)
                created_concepts.append(concept.name)
                
                # í•˜ìœ„ ì„¹ì…˜ ì²­í¬ ìƒì„±
                if concept.subsections:
                    self.create_subsection_chunks(concept)
                
                # ê´€ê³„ ì¶”ì¶œ
                relationships = self.extract_relationships(section_content)
                for rel in relationships:
                    rel.from_concept = concept_name
                    all_relationships.append(rel)
                
                print(f"âœ… ì™„ë£Œ: {concept_name} (ì²­í¬ID: {chunk_id[:8]}...)")
                
            except Exception as e:
                print(f"âŒ ì—ëŸ¬: {concept_name} - {e}")
        
        # ê´€ê³„ ìƒì„±
        print(f"\nğŸ”— ê´€ê³„ ìƒì„± ì¤‘: {len(all_relationships)}ê°œ")
        self.create_relationships(all_relationships)
        
        # ìš”ì•½ ì¶œë ¥
        print(f"\nğŸ‰ íŒŒì‹± ì™„ë£Œ!")
        print(f"   - ìƒì„±ëœ ê°œë…: {len(created_concepts)}ê°œ")
        print(f"   - ì²˜ë¦¬ëœ ê´€ê³„: {len(all_relationships)}ê°œ")
        print(f"   - ì†ŒìŠ¤ íŒŒì¼: {Path(markdown_file).name}")
        
        return created_concepts, all_relationships

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    if len(sys.argv) < 2:
        print("ì‚¬ìš©ë²•: python scripts/markdown_to_neo4j_parser.py <input_file>")
        sys.exit(1)
    
    input_file = Path(sys.argv[1])
    
    if not input_file.exists():
        print(f"âŒ ì…ë ¥ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {input_file}")
        sys.exit(1)
    
    # Neo4j ì—°ê²° ì •ë³´
    neo4j_uri = os.getenv("NEO4J_URI")
    neo4j_username = os.getenv("NEO4J_USERNAME") 
    neo4j_password = os.getenv("NEO4J_PASSWORD")
    
    if not all([neo4j_uri, neo4j_username, neo4j_password]):
        print("âŒ Neo4j ì—°ê²° ì •ë³´ê°€ í•„ìš”í•©ë‹ˆë‹¤ (.env íŒŒì¼ í™•ì¸)")
        sys.exit(1)
    
    try:
        # íŒŒì„œ ìƒì„± ë° ì‹¤í–‰
        parser = MarkdownToNeo4jParser(neo4j_uri, neo4j_username, neo4j_password)
        concepts, relationships = parser.parse_and_store(str(input_file))
        
        print(f"\nâœ… Neo4j ì €ì¥ ì™„ë£Œ!")
        print(f"   - URI: {neo4j_uri}")
        print(f"   - ê°œë…ë“¤: {', '.join(concepts[:5])}{'...' if len(concepts) > 5 else ''}")
        
    except Exception as e:
        print(f"âŒ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main() 