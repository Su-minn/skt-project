#!/usr/bin/env python3
"""
ë§ˆí¬ë‹¤ìš´ íŒŒì¼ ë‹¨ê³„ë³„ LLM ì •ì œ ìŠ¤í¬ë¦½íŠ¸
 
ê¸°ëŠ¥:
- 1ë‹¨ê³„: ê¸°ë³¸ ì •ì œ (í™˜ê²½ ì„¤ì •, ì´ë¯¸ì§€, ì‹¤í–‰ ê²°ê³¼, ë””ë²„ê¹… ì½”ë“œ ì œê±°)
- 2ë‹¨ê³„: ê³„ì¸µ êµ¬ì¡° ì¡°ì •
- 3ë‹¨ê³„: ê°œë… ì„¤ëª… ê°œì„   
- 4ë‹¨ê³„: ê°œë… ê°„ ê´€ê³„ ëª…ì‹œí™”
 
ì‚¬ìš©ë²•:
    python scripts/markdown_llm_refiner.py <input_file> [output_file]
"""

import sys
import json
from pathlib import Path
from typing import Dict, List, Optional
from langchain_openai import ChatOpenAI
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain.schema import HumanMessage, SystemMessage
from dotenv import load_dotenv

load_dotenv()


class MarkdownLLMRefiner:
    def __init__(self, openai_model_name: str = "gpt-4.1", google_model_name: str = "gemini-2.0-flash"):
        self.openai_llm = ChatOpenAI(model=openai_model_name, temperature=0.1)
        self.google_llm = ChatGoogleGenerativeAI(model=google_model_name, temperature=0.1)
    
    def step1_basic_cleanup(self, content: str) -> str:
        """1ë‹¨ê³„: ê¸°ë³¸ ì •ì œ - í™˜ê²½ ì„¤ì •, ì´ë¯¸ì§€, ë””ë²„ê¹… ì½”ë“œ ì œê±°"""
        print("ğŸ§¹ 1ë‹¨ê³„: ê¸°ë³¸ ì •ì œ ì‹œì‘...")
        
        system_prompt = """
ë‹¹ì‹ ì€ LangGraph í•™ìŠµ ìë£Œì˜ ë§ˆí¬ë‹¤ìš´ ê¸°ë³¸ ì •ì œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ë‹¤ìŒ ì‘ì—…ë§Œ ìˆ˜í–‰í•´ì£¼ì„¸ìš”:

## ğŸ§¹ ê¸°ë³¸ ì •ì œ (ìë™ ì œê±°)

**í™˜ê²½ ì„¤ì • ì œê±°**:
- "í™˜ê²½ ì„¤ì • ë° ì¤€ë¹„" ì„¹ì…˜ ì „ì²´ ì œê±°
- "Env í™˜ê²½ë³€ìˆ˜", "ê¸°ë³¸ ë¼ì´ë¸ŒëŸ¬ë¦¬", "langfuse", "ì½œë°± í•¸ë“¤ëŸ¬" ê´€ë ¨ ì„¹ì…˜ ì œê±°
- import ë¬¸ ì¤‘ í™˜ê²½ ì„¤ì • ê´€ë ¨ë§Œ ì œê±° (í•µì‹¬ ê¸°ëŠ¥ importëŠ” ìœ ì§€)

**ë¶ˆí•„ìš”í•œ ìš”ì†Œ ì œê±°**:
- ëª¨ë“  ì´ë¯¸ì§€ íƒœê·¸ ì œê±° (![...](...), <img>)
- ì‹¤í–‰ ê²°ê³¼ ì¤‘ ì˜ë¯¸ ì—†ëŠ” ì¶œë ¥ ì œê±° (ë‹¨ìˆœ True/False, ë”•ì…”ë„ˆë¦¬ ì¶œë ¥)
- ë””ë²„ê¹…ìš© ì½”ë“œ ì œê±° (langfuse_handler, display(Image), í…ŒìŠ¤íŠ¸ìš© ì£¼ì„)
- ë¹ˆ ì½”ë“œ ë¸”ë¡ ë° ì—°ì†ëœ ë¹ˆ ì¤„ ì •ë¦¬

## âš ï¸ ì£¼ì˜ì‚¬í•­
- í•µì‹¬ ì •ë³´ì™€ ì½”ë“œëŠ” ì ˆëŒ€ ì‚­ì œí•˜ì§€ ë§ê³  ê·¸ëŒ€ë¡œ ìœ ì§€
- í•™ìŠµì— í•„ìš”í•œ import ë¬¸ì€ ìœ ì§€
- ì‹¤ìŠµ ì½”ë“œì™€ ì˜ë¯¸ ìˆëŠ” ê²°ê³¼ëŠ” ë³´ì¡´
- ì›ë³¸ì˜ ë‚´ìš©ê³¼ êµ¬ì¡°ëŠ” ìµœëŒ€í•œ ë³´ì¡´í•˜ê³  ë¶ˆí•„ìš”í•œ ë¶€ë¶„ë§Œ ì œê±°
"""
        
        human_prompt = f"""
ë‹¤ìŒ LangGraph í•™ìŠµ ìë£Œì—ì„œ í™˜ê²½ ì„¤ì •, ì´ë¯¸ì§€, ë””ë²„ê¹… ì½”ë“œ ë“± ë¶ˆí•„ìš”í•œ ìš”ì†Œë§Œ ì œê±°í•´ì£¼ì„¸ìš”:

{content}
"""
        
        messages = [
            SystemMessage(content=system_prompt),
            HumanMessage(content=human_prompt)
        ]
        
        response = self.google_llm.invoke(messages)
        print("âœ… 1ë‹¨ê³„: ê¸°ë³¸ ì •ì œ ì™„ë£Œ")
        return response.content
    
    def step2_structure_improvement(self, content: str) -> str:
        """2ë‹¨ê³„: êµ¬ì¡° ê°œì„  - ê³„ì¸µ ì¡°ì • ë° ë‚´ìš© êµ¬ì¡°í™”"""
        print("ğŸ“‹ 2ë‹¨ê³„: êµ¬ì¡° ê°œì„  ì‹œì‘...")
        
        system_prompt = """
ë‹¹ì‹ ì€ LangGraph í•™ìŠµ ìë£Œì˜ ë§ˆí¬ë‹¤ìš´ êµ¬ì¡°ë¥¼ ê°œì„ í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ë‹¤ìŒ ì‘ì—…ë§Œ ìˆ˜í–‰í•´ì£¼ì„¸ìš”:

## ğŸ“‹ êµ¬ì¡° ê°œì„ 

**ê³„ì¸µ êµ¬ì¡° ì¡°ì •**:
- í•µì‹¬ ê°œë… (StateGraph, Command ë“±)ì„ ## ë ˆë²¨ë¡œ
- í•˜ìœ„ ê°œë… (State, Node, Graph ë“±)ì„ ### ë ˆë²¨ë¡œ  
- êµ¬í˜„ ì„¸ë¶€ì‚¬í•­ì„ #### ë ˆë²¨ë¡œ
- ë…¼ë¦¬ì  í•™ìŠµ ìˆœì„œ: ê¸°ì´ˆ ê°œë… â†’ ì‹¬í™” ê°œë… â†’ ì‹¤ìŠµ â†’ ë„êµ¬

**ë‚´ìš© êµ¬ì¡°í™”**:
- ê°œë… ì„¤ëª…ê³¼ ì½”ë“œë¥¼ ëª…í™•íˆ ë¶„ë¦¬
- ê° ì„¹ì…˜ì˜ ëª©ì ì„ ëª…ì‹œ
- ì¼ê´€ëœ í‘œê¸°ë²• ì‚¬ìš©

## âš ï¸ ì£¼ì˜ì‚¬í•­
- ë‚´ìš©ì€ ë³€ê²½í•˜ì§€ ë§ê³  êµ¬ì¡°ì™€ ê³„ì¸µë§Œ ì¡°ì •
- ëª¨ë“  ì›ë³¸ ì •ë³´ ë³´ì¡´
- í•™ìŠµ íë¦„ ìœ ì§€
"""
        
        human_prompt = f"""
ë‹¤ìŒ ë§ˆí¬ë‹¤ìš´ì˜ ê³„ì¸µ êµ¬ì¡°ì™€ ë‚´ìš© êµ¬ì¡°ë¥¼ ê°œì„ í•´ì£¼ì„¸ìš”:

{content}
"""
        
        messages = [
            SystemMessage(content=system_prompt),
            HumanMessage(content=human_prompt)
        ]
        
        response = self.openai_llm.invoke(messages)
        print("âœ… 2ë‹¨ê³„: êµ¬ì¡° ê°œì„  ì™„ë£Œ")
        return response.content
    
    def step3_concept_improvement(self, content: str) -> str:
        """3ë‹¨ê³„: ê°œë… ì„¤ëª… ê°œì„ """
        print("ğŸ“ 3ë‹¨ê³„: ê°œë… ì„¤ëª… ê°œì„  ì‹œì‘...")
        
        system_prompt = """
ë‹¹ì‹ ì€ LangGraph ê¸°ìˆ  ë¬¸ì„œ ì‘ì„± ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ë‹¤ìŒ ì‘ì—…ë§Œ ìˆ˜í–‰í•´ì£¼ì„¸ìš”:

## ğŸ“ ê°œë… ì„¤ëª… ê°œì„ 

ê° ì£¼ìš” ê°œë…ì„ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì •ë¦¬:

```markdown
## [ê°œë…ëª…]

**ì •ì˜**: [ëª…í™•í•œ ì •ì˜]

**íŠ¹ì§•**:
- [ì£¼ìš” íŠ¹ì§• 1]
- [ì£¼ìš” íŠ¹ì§• 2]

**í™œìš©**: [ì–´ë–¤ ìƒí™©ì—ì„œ ì‚¬ìš©ë˜ëŠ”ì§€]

### ì½”ë“œ ì˜ˆì œ
[ê¸°ì¡´ ì½”ë“œì™€ ì„¤ëª… ìœ ì§€]

### ì‹¤í–‰ ê²°ê³¼
[ì‹¤í–‰ ê²°ê³¼ ìœ ì§€]
```

## âš ï¸ ì£¼ì˜ì‚¬í•­
- ê¸°ì¡´ ì½”ë“œì™€ ì˜ˆì œëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€
- ì„¤ëª…ë§Œ ëª…í™•í•˜ê³  ì¼ê´€ë˜ê²Œ ê°œì„ 
- ìƒˆë¡œìš´ ë‚´ìš© ì¶”ê°€ ê¸ˆì§€
"""
        
        human_prompt = f"""
ë‹¤ìŒ ë§ˆí¬ë‹¤ìš´ì˜ ê°œë… ì„¤ëª…ì„ ìœ„ í˜•ì‹ì— ë§ê²Œ ê°œì„ í•´ì£¼ì„¸ìš”:

{content}
"""
        
        messages = [
            SystemMessage(content=system_prompt),
            HumanMessage(content=human_prompt)
        ]
        
        response = self.google_llm.invoke(messages)
        print("âœ… 3ë‹¨ê³„: ê°œë… ì„¤ëª… ê°œì„  ì™„ë£Œ")
        return response.content
    
    def step4_relationship_mapping(self, content: str) -> str:
        """4ë‹¨ê³„: ê°œë… ê°„ ê´€ê³„ ëª…ì‹œí™”"""
        print("ğŸ”— 4ë‹¨ê³„: ê´€ê³„ ëª…ì‹œí™” ì‹œì‘...")
        
        system_prompt = """
ë‹¹ì‹ ì€ LangGraph ì§€ì‹ ê·¸ë˜í”„ ì„¤ê³„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ë‹¤ìŒ ì‘ì—…ë§Œ ìˆ˜í–‰í•´ì£¼ì„¸ìš”:

## ğŸ”— ê´€ê³„ ëª…ì‹œí™”

ê° ê°œë…ì— ë‹¤ìŒ ê´€ê³„ ì •ë³´ë¥¼ ì¶”ê°€:

**ì„ í–‰ ê°œë…**: [ì´ ê°œë…ì„ ì´í•´í•˜ê¸° ìœ„í•´ ë¨¼ì € ì•Œì•„ì•¼ í•  ê°œë…ë“¤]
**ì—°ê´€ ê°œë…**: [í•¨ê»˜ ì‚¬ìš©ë˜ê±°ë‚˜ ê´€ë ¨ëœ ê°œë…ë“¤]

ê´€ê³„ ìœ í˜•:
- PREREQUISITE: ì„ í–‰ í•™ìŠµ í•„ìš”
- BUILDS_UPON: ê¸°ë°˜ìœ¼ë¡œ í™•ì¥
- IMPLEMENTS: ì½”ë“œê°€ ê°œë… êµ¬í˜„
- TEACHES: íŠœí† ë¦¬ì–¼ì´ ê°œë… ê°€ë¥´ì¹¨
- SUPPORTS: ë„êµ¬ê°€ ê°œë… ì§€ì›

## âš ï¸ ì£¼ì˜ì‚¬í•­
- ê¸°ì¡´ ë‚´ìš©ì€ ê·¸ëŒ€ë¡œ ìœ ì§€
- ê° ê°œë… ì„¹ì…˜ì— ê´€ê³„ ì •ë³´ë§Œ ì¶”ê°€
- ì‹¤ì œ ë¬¸ì„œì— ë‚˜íƒ€ë‚œ ê°œë…ë“¤ ê°„ì˜ ê´€ê³„ë§Œ ëª…ì‹œ
"""
        
        human_prompt = f"""
ë‹¤ìŒ ë§ˆí¬ë‹¤ìš´ì—ì„œ ê°œë… ê°„ ê´€ê³„ë¥¼ ë¶„ì„í•˜ê³  ëª…ì‹œí•´ì£¼ì„¸ìš”:

{content}
"""
        
        messages = [
            SystemMessage(content=system_prompt),
            HumanMessage(content=human_prompt)
        ]
        
        response = self.google_llm.invoke(messages)
        print("âœ… 4ë‹¨ê³„: ê´€ê³„ ëª…ì‹œí™” ì™„ë£Œ")
        return response.content
    
    def refine_step_by_step(self, content: str) -> str:
        """4ë‹¨ê³„ì— ê±¸ì³ ìˆœì°¨ì ìœ¼ë¡œ ì •ì œë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤."""
        original_lines = len(content.splitlines())
        original_size = len(content)
        
        print(f"ğŸ“Š ì›ë³¸: {original_lines}ì¤„, {original_size:,}ì")
        print("=" * 50)
        
        # 1ë‹¨ê³„: ê¸°ë³¸ ì •ì œ
        content = self.step1_basic_cleanup(content)
        step1_lines = len(content.splitlines())
        step1_size = len(content)
        print(f"ğŸ“Š 1ë‹¨ê³„ í›„: {step1_lines}ì¤„ ({step1_lines-original_lines:+d}), {step1_size:,}ì ({((step1_size-original_size)/original_size)*100:+.1f}%)")
        print("=" * 50)
        
        # 2ë‹¨ê³„: êµ¬ì¡° ê°œì„   
        content = self.step2_structure_improvement(content)
        step2_lines = len(content.splitlines())
        step2_size = len(content)
        print(f"ğŸ“Š 2ë‹¨ê³„ í›„: {step2_lines}ì¤„ ({step2_lines-step1_lines:+d}), {step2_size:,}ì ({((step2_size-step1_size)/step1_size)*100:+.1f}%)")
        print("=" * 50)
        
        # 3ë‹¨ê³„: ê°œë… ì„¤ëª… ê°œì„ 
        content = self.step3_concept_improvement(content)
        step3_lines = len(content.splitlines())
        step3_size = len(content)
        print(f"ğŸ“Š 3ë‹¨ê³„ í›„: {step3_lines}ì¤„ ({step3_lines-step2_lines:+d}), {step3_size:,}ì ({((step3_size-step2_size)/step2_size)*100:+.1f}%)")
        print("=" * 50)
        
        # 4ë‹¨ê³„: ê´€ê³„ ëª…ì‹œí™”
        content = self.step4_relationship_mapping(content)
        final_lines = len(content.splitlines())
        final_size = len(content)
        print(f"ğŸ“Š 4ë‹¨ê³„ í›„: {final_lines}ì¤„ ({final_lines-step3_lines:+d}), {final_size:,}ì ({((final_size-step3_size)/step3_size)*100:+.1f}%)")
        print("=" * 50)
        
        # ìµœì¢… ìš”ì•½
        total_lines_change = final_lines - original_lines
        total_size_change = final_size - original_size
        total_size_change_percent = (total_size_change / original_size) * 100 if original_size > 0 else 0
        
        print(f"\nğŸ“Š ìµœì¢… ìš”ì•½:")
        print(f"   ì›ë³¸ â†’ ìµœì¢…: {original_lines}ì¤„ â†’ {final_lines}ì¤„ ({total_lines_change:+d}ì¤„)")
        print(f"   í¬ê¸° ë³€í™”: {original_size:,}ì â†’ {final_size:,}ì ({total_size_change_percent:+.1f}%)")
        
        return content

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    if len(sys.argv) < 2:
        print("ì‚¬ìš©ë²•: python scripts/markdown_llm_refiner.py <input_file> [output_file]")
        sys.exit(1)
    
    input_file = Path(sys.argv[1])
    output_file = Path(sys.argv[2]) if len(sys.argv) > 2 else input_file.with_suffix('.refined.md')
    
    if not input_file.exists():
        print(f"âŒ ì…ë ¥ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {input_file}")
        sys.exit(1)
    
    print(f"ğŸ“„ ì…ë ¥ íŒŒì¼: {input_file}")
    print(f"ğŸ“„ ì¶œë ¥ íŒŒì¼: {output_file}")
    print()
    
    try:
        # íŒŒì¼ ì½ê¸°
        with open(input_file, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # ë‹¨ê³„ë³„ ì •ì œ
        print("ğŸ¤– ë‹¨ê³„ë³„ LLM ì •ì œ ì‹œì‘...")
        refiner = MarkdownLLMRefiner()
        refined_content = refiner.refine_step_by_step(content)
        
        # íŒŒì¼ ì €ì¥
        output_file.parent.mkdir(parents=True, exist_ok=True)
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(refined_content)
        
        print(f"\nğŸ‰ ë‹¨ê³„ë³„ ì •ì œ ì™„ë£Œ!")
        print(f"ğŸ’¾ ì €ì¥ ìœ„ì¹˜: {output_file}")
        print(f"\nâœ… ì™„ë£Œëœ ë‹¨ê³„:")
        print(f"  1ï¸âƒ£ ê¸°ë³¸ ì •ì œ: í™˜ê²½ ì„¤ì •, ì´ë¯¸ì§€, ë””ë²„ê¹… ì½”ë“œ ì œê±°")
        print(f"  2ï¸âƒ£ êµ¬ì¡° ê°œì„ : ê³„ì¸µ ì¡°ì •, ë‚´ìš© êµ¬ì¡°í™”")
        print(f"  3ï¸âƒ£ ê°œë… ê°œì„ : ì •ì˜, íŠ¹ì§•, í™œìš© ëª…í™•í™”")
        print(f"  4ï¸âƒ£ ê´€ê³„ ëª…ì‹œ: ì„ í–‰/ì—°ê´€ ê°œë… ë§¤í•‘")
        
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        sys.exit(1)

if __name__ == "__main__":
    main()
