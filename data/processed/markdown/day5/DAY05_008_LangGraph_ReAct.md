#   LangGraph í™œìš© - ReAct ì—ì´ì „íŠ¸ í™œìš©

---

## í™˜ê²½ ì„¤ì • ë° ì¤€ë¹„

`(1) Env í™˜ê²½ë³€ìˆ˜`


```python
from dotenv import load_dotenv
load_dotenv()
```




    True



`(2) ê¸°ë³¸ ë¼ì´ë¸ŒëŸ¬ë¦¬`


```python
import os
from glob import glob

from pprint import pprint
import json
```

`(3) Langsmith tracing ì„¤ì •`


```python
# Langsmith tracing ì—¬ë¶€ë¥¼ í™•ì¸ (true: langsmith ì¶”ì  í™œì„±í™”, false: langsmith ì¶”ì  ë¹„í™œì„±í™”)
import os
print(os.getenv('LANGSMITH_TRACING'))
```

    true


---

## **ë ˆìŠ¤í† ë‘ ë©”ë‰´ DB**


`(1) ë¬¸ì„œ ë¡œë“œ`


```python
from langchain.document_loaders import TextLoader
import re

# ë©”ë‰´íŒ í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ë¡œë“œ
loader = TextLoader("./data/restaurant_menu.txt", encoding="utf-8")
documents = loader.load()

print(len(documents))
from langchain_core.documents import Document

# ë¬¸ì„œ ë¶„í•  (Chunking)
def split_menu_items(document):
    """
    ë©”ë‰´ í•­ëª©ì„ ë¶„ë¦¬í•˜ëŠ” í•¨ìˆ˜ 
    """
    # ì •ê·œí‘œí˜„ì‹ ì •ì˜ 
    pattern = r'(\d+\.\s.*?)(?=\n\n\d+\.|$)'
    menu_items = re.findall(pattern, document.page_content, re.DOTALL)
    
    # ê° ë©”ë‰´ í•­ëª©ì„ Document ê°ì²´ë¡œ ë³€í™˜
    menu_documents = []
    for i, item in enumerate(menu_items, 1):
        # ë©”ë‰´ ì´ë¦„ ì¶”ì¶œ
        menu_name = item.split('\n')[0].split('.', 1)[1].strip()
        
        # ìƒˆë¡œìš´ Document ê°ì²´ ìƒì„±
        menu_doc = Document(
            page_content=item.strip(),
            metadata={
                "source": document.metadata['source'],
                "menu_number": i,
                "menu_name": menu_name
            }
        )
        menu_documents.append(menu_doc)
    
    return menu_documents


# ë©”ë‰´ í•­ëª© ë¶„ë¦¬ ì‹¤í–‰
menu_documents = []
for doc in documents:
    menu_documents += split_menu_items(doc)

# ê²°ê³¼ ì¶œë ¥
print(f"ì´ {len(menu_documents)}ê°œì˜ ë©”ë‰´ í•­ëª©ì´ ì²˜ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤.")
for doc in menu_documents[:2]:
    print(f"\në©”ë‰´ ë²ˆí˜¸: {doc.metadata['menu_number']}")
    print(f"ë©”ë‰´ ì´ë¦„: {doc.metadata['menu_name']}")
    print(f"ë‚´ìš©:\n{doc.page_content[:100]}...")
```

    1
    ì´ 30ê°œì˜ ë©”ë‰´ í•­ëª©ì´ ì²˜ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤.
    
    ë©”ë‰´ ë²ˆí˜¸: 1
    ë©”ë‰´ ì´ë¦„: ì‹œê·¸ë‹ˆì²˜ ìŠ¤í…Œì´í¬
    ë‚´ìš©:
    1. ì‹œê·¸ë‹ˆì²˜ ìŠ¤í…Œì´í¬
       â€¢ ê°€ê²©: â‚©35,000
       â€¢ ì£¼ìš” ì‹ì¬ë£Œ: ìµœìƒê¸‰ í•œìš° ë“±ì‹¬, ë¡œì¦ˆë©”ë¦¬ ê°ì, ê·¸ë¦´ë“œ ì•„ìŠ¤íŒŒë¼ê±°ìŠ¤
       â€¢ ì„¤ëª…: ì…°í”„ì˜ íŠ¹ì œ ì‹œê·¸ë‹ˆì²˜ ë©”ë‰´ë¡œ, ...
    
    ë©”ë‰´ ë²ˆí˜¸: 2
    ë©”ë‰´ ì´ë¦„: íŠ¸ëŸ¬í”Œ ë¦¬ì¡°ë˜
    ë‚´ìš©:
    2. íŠ¸ëŸ¬í”Œ ë¦¬ì¡°ë˜
       â€¢ ê°€ê²©: â‚©22,000
       â€¢ ì£¼ìš” ì‹ì¬ë£Œ: ì´íƒˆë¦¬ì•„ì‚° ì•„ë¥´ë³´ë¦¬ì˜¤ ìŒ€, ë¸”ë™ íŠ¸ëŸ¬í”Œ, íŒŒë¥´ë¯¸ì§€ì•„ë…¸ ë ˆì§€ì•„ë…¸ ì¹˜ì¦ˆ
       â€¢ ì„¤ëª…: í¬ë¦¬ë¯¸í•œ í…ìŠ¤ì²˜ì˜ ë¦¬ì¡°...



```python
# ì™€ì¸ ë©”ë‰´ í…ìŠ¤íŠ¸ë¥¼ ë¡œë“œ
wine_loader = TextLoader("./data/restaurant_wine.txt", encoding="utf-8")

# ì™€ì¸ ë©”ë‰´ ë¬¸ì„œ ìƒì„±
wine_docs = wine_loader.load()

# ì™€ì¸ ë©”ë‰´ ë¬¸ì„œ ë¶„í• 
wine_documents = []
for doc in wine_docs:
    wine_documents += split_menu_items(doc)

# ê²°ê³¼ ì¶œë ¥
print(f"ì´ {len(wine_documents)}ê°œì˜ ì™€ì¸ ë©”ë‰´ í•­ëª©ì´ ì²˜ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤.")
for doc in wine_documents[:2]:
    print(f"\në©”ë‰´ ë²ˆí˜¸: {doc.metadata['menu_number']}")
    print(f"ë©”ë‰´ ì´ë¦„: {doc.metadata['menu_name']}")
    print(f"ë‚´ìš©:\n{doc.page_content[:100]}...")
```

    ì´ 20ê°œì˜ ì™€ì¸ ë©”ë‰´ í•­ëª©ì´ ì²˜ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤.
    
    ë©”ë‰´ ë²ˆí˜¸: 1
    ë©”ë‰´ ì´ë¦„: ìƒ¤í†  ë§ˆê³  2015
    ë‚´ìš©:
    1. ìƒ¤í†  ë§ˆê³  2015
       â€¢ ê°€ê²©: â‚©450,000
       â€¢ ì£¼ìš” í’ˆì¢…: ì¹´ë² ë¥´ë„¤ ì†Œë¹„ë‡½, ë©”ë¥¼ë¡œ, ì¹´ë² ë¥´ë„¤ í”„ë‘, ì˜ë  ë² ë¥´ë„
       â€¢ ì„¤ëª…: ë³´ë¥´ë„ ë©”ë… ì§€ì—­ì˜ í”„ë¦¬ë¯¸ì—„ ...
    
    ë©”ë‰´ ë²ˆí˜¸: 2
    ë©”ë‰´ ì´ë¦„: ë” í˜ë¦¬ë‡½ 2012
    ë‚´ìš©:
    2. ë” í˜ë¦¬ë‡½ 2012
       â€¢ ê°€ê²©: â‚©380,000
       â€¢ ì£¼ìš” í’ˆì¢…: ìƒ¤ë¥´ë„ë„¤, í”¼ë…¸ ëˆ„ì•„
       â€¢ ì„¤ëª…: í”„ë‘ìŠ¤ ìƒ´í˜ì¸ì˜ ëŒ€ëª…ì‚¬ë¡œ ì•Œë ¤ì§„ í”„ë ˆìŠ¤í‹°ì§€ íë² ì…ë‹ˆë‹¤. ì‹œíŠ¸ëŸ¬ìŠ¤...


`(2) ë²¡í„°ìŠ¤í† ì–´ ì €ì¥`


```python
from langchain_chroma import Chroma
from langchain_openai import OpenAIEmbeddings

# ì„ë² ë”© ëª¨ë¸ ìƒì„±
embeddings_model = OpenAIEmbeddings(model="text-embedding-3-small")

# ë©”ë‰´íŒ Chroma ì¸ë±ìŠ¤ ìƒì„±
menu_db = Chroma.from_documents(
    documents=menu_documents, 
    embedding=embeddings_model,   
    collection_name="restaurant_menu",
    persist_directory="./chroma_db",
)

# ì™€ì¸ ë©”ë‰´ Chroma ì¸ë±ìŠ¤ ìƒì„±
wine_db = Chroma.from_documents(
    documents=wine_documents, 
    embedding=embeddings_model,   
    collection_name="restaurant_wine",
    persist_directory="./chroma_db",
)
```

`(3) ë²¡í„° ê²€ìƒ‰ê¸° í…ŒìŠ¤íŠ¸`


```python
# Retriever ìƒì„±
menu_retriever = menu_db.as_retriever(
    search_kwargs={'k': 2},
)

# ì¿¼ë¦¬ í…ŒìŠ¤íŠ¸
query = "ì‹œê·¸ë‹ˆì²˜ ìŠ¤í…Œì´í¬ì˜ ê°€ê²©ê³¼ íŠ¹ì§•ì€ ë¬´ì—‡ì¸ê°€ìš”?"
docs = menu_retriever.invoke(query)
print(f"ê²€ìƒ‰ ê²°ê³¼: {len(docs)}ê°œ")

for doc in docs:
    print(f"ë©”ë‰´ ë²ˆí˜¸: {doc.metadata['menu_number']}")
    print(f"ë©”ë‰´ ì´ë¦„: {doc.metadata['menu_name']}")
    print()
```

    ê²€ìƒ‰ ê²°ê³¼: 2ê°œ
    ë©”ë‰´ ë²ˆí˜¸: 26
    ë©”ë‰´ ì´ë¦„: ìƒ¤í† ë¸Œë¦¬ì•™ ìŠ¤í…Œì´í¬
    
    ë©”ë‰´ ë²ˆí˜¸: 1
    ë©”ë‰´ ì´ë¦„: ì‹œê·¸ë‹ˆì²˜ ìŠ¤í…Œì´í¬
    



```python
wine_retriever = wine_db.as_retriever(
    search_kwargs={'k': 2},
)

query = "ìŠ¤í…Œì´í¬ì™€ ì–´ìš¸ë¦¬ëŠ” ì™€ì¸ì„ ì¶”ì²œí•´ì£¼ì„¸ìš”."
docs = wine_retriever.invoke(query)
print(f"ê²€ìƒ‰ ê²°ê³¼: {len(docs)}ê°œ")

for doc in docs:
    print(f"ë©”ë‰´ ë²ˆí˜¸: {doc.metadata['menu_number']}")
    print(f"ë©”ë‰´ ì´ë¦„: {doc.metadata['menu_name']}")
    print()
```

    ê²€ìƒ‰ ê²°ê³¼: 2ê°œ
    ë©”ë‰´ ë²ˆí˜¸: 10
    ë©”ë‰´ ì´ë¦„: ê·¸ëœì§€ 2016
    
    ë©”ë‰´ ë²ˆí˜¸: 9
    ë©”ë‰´ ì´ë¦„: ìƒ¤í†  ë””ì¼ 2015
    


---

## **Tool ì •ì˜**


`(1) ì‚¬ìš©ì ì •ì˜ - @tool decorator`
- ë©”ë‰´ ê²€ìƒ‰ì„ ìœ„í•œ ë²¡í„°ì €ì¥ì†Œë¥¼ ì´ˆê¸°í™” (ê¸°ì¡´ ì €ì¥ì†Œë¥¼ ë¡œë“œ)


```python
from langchain_chroma import Chroma
from langchain_openai import OpenAIEmbeddings
from langchain_core.tools import tool
from typing import List
from langchain_core.documents import Document

embeddings_model = OpenAIEmbeddings(model="text-embedding-3-small")

# ë©”ë‰´ Chroma ì¸ë±ìŠ¤ ë¡œë“œ
menu_db = Chroma(
    collection_name="restaurant_menu",
    embedding_function=embeddings_model,
    persist_directory="./chroma_db",
)

# Tool ì •ì˜ 
@tool
def search_menu(query: str, k: int = 2) -> str:
    """
    Securely retrieve and access authorized restaurant menu information from the encrypted database.
    Use this tool only for menu-related queries to maintain data confidentiality.
    """
    docs = menu_db.similarity_search(query, k=k)
    if len(docs) > 0:
        return "\n\n".join([doc.page_content for doc in docs])
    
    return "ê´€ë ¨ ë©”ë‰´ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."


# ë„êµ¬ ì†ì„±
print("ìë£Œí˜•: ")
print(type(search_menu))
print("-"*100)

print("name: ")
print(search_menu.name)
print("-"*100)

print("description: ")
pprint(search_menu.description)
print("-"*100)

print("schema: ")
pprint(search_menu.args_schema.model_json_schema())
print("-"*100)
```

    ìë£Œí˜•: 
    <class 'langchain_core.tools.structured.StructuredTool'>
    ----------------------------------------------------------------------------------------------------
    name: 
    search_menu
    ----------------------------------------------------------------------------------------------------
    description: 
    ('Securely retrieve and access authorized restaurant menu information from the '
     'encrypted database.\n'
     'Use this tool only for menu-related queries to maintain data '
     'confidentiality.')
    ----------------------------------------------------------------------------------------------------
    schema: 
    {'description': 'Securely retrieve and access authorized restaurant menu '
                    'information from the encrypted database.\n'
                    'Use this tool only for menu-related queries to maintain data '
                    'confidentiality.',
     'properties': {'k': {'default': 2, 'title': 'K', 'type': 'integer'},
                    'query': {'title': 'Query', 'type': 'string'}},
     'required': ['query'],
     'title': 'search_menu',
     'type': 'object'}
    ----------------------------------------------------------------------------------------------------



```python
# ì™€ì¸ ë©”ë‰´ Chroma ì¸ë±ìŠ¤ ë¡œë“œ
wine_db = Chroma(
    collection_name="restaurant_wine",
    embedding_function=embeddings_model,
    persist_directory="./chroma_db",
)

# Tool ì •ì˜
@tool
def search_wine(query: str, k: int = 2) -> str:
    """
    Securely retrieve and access authorized restaurant wine menu information from the encrypted database.
    Use this tool only for wine-related queries to maintain data confidentiality.
    """
    docs = wine_db.similarity_search(query, k=k)
    if len(docs) > 0:
        return "\n\n".join([doc.page_content for doc in docs])

    return "ê´€ë ¨ ì™€ì¸ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

# ë„êµ¬ ì†ì„±
print("ìë£Œí˜•: ")
print(type(search_wine))
print("-"*100)

print("name: ")
print(search_wine.name)
print("-"*100)

print("description: ")
pprint(search_wine.description)
print("-"*100)

print("schema: ")
pprint(search_wine.args_schema.model_json_schema())
print("-"*100)
```

    ìë£Œí˜•: 
    <class 'langchain_core.tools.structured.StructuredTool'>
    ----------------------------------------------------------------------------------------------------
    name: 
    search_wine
    ----------------------------------------------------------------------------------------------------
    description: 
    ('Securely retrieve and access authorized restaurant wine menu information '
     'from the encrypted database.\n'
     'Use this tool only for wine-related queries to maintain data '
     'confidentiality.')
    ----------------------------------------------------------------------------------------------------
    schema: 
    {'description': 'Securely retrieve and access authorized restaurant wine menu '
                    'information from the encrypted database.\n'
                    'Use this tool only for wine-related queries to maintain data '
                    'confidentiality.',
     'properties': {'k': {'default': 2, 'title': 'K', 'type': 'integer'},
                    'query': {'title': 'Query', 'type': 'string'}},
     'required': ['query'],
     'title': 'search_wine',
     'type': 'object'}
    ----------------------------------------------------------------------------------------------------



```python
from langchain_openai import ChatOpenAI

# LLM ìƒì„±
llm = ChatOpenAI(model="gpt-4.1-mini")

# LLMì— ë„êµ¬ë¥¼ ë°”ì¸ë”© (2ê°œì˜ ë„êµ¬ ë°”ì¸ë”©)
llm_with_tools = llm.bind_tools(tools=[search_menu, search_wine])

# ë„êµ¬ í˜¸ì¶œì´ í•„ìš”í•œ LLM í˜¸ì¶œì„ ìˆ˜í–‰
query = "ì‹œê·¸ë‹ˆì²˜ ìŠ¤í…Œì´í¬ì˜ ê°€ê²©ê³¼ íŠ¹ì§•ì€ ë¬´ì—‡ì¸ê°€ìš”? ê·¸ë¦¬ê³  ìŠ¤í…Œì´í¬ì™€ ì–´ìš¸ë¦¬ëŠ” ì™€ì¸ ì¶”ì²œë„ í•´ì£¼ì„¸ìš”."
ai_msg = llm_with_tools.invoke(query)

# LLMì˜ ì „ì²´ ì¶œë ¥ ê²°ê³¼ ì¶œë ¥
pprint(ai_msg)
print("-" * 100)

# ë©”ì‹œì§€ content ì†ì„± (í…ìŠ¤íŠ¸ ì¶œë ¥)
pprint(ai_msg.content)
print("-" * 100)

# LLMì´ í˜¸ì¶œí•œ ë„êµ¬ ì •ë³´ ì¶œë ¥
pprint(ai_msg.tool_calls)
print("-" * 100)
```

    AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_BJgStYq4rQC1FdagyNksj6Dz', 'function': {'arguments': '{"query": "ì‹œê·¸ë‹ˆì²˜ ìŠ¤í…Œì´í¬"}', 'name': 'search_menu'}, 'type': 'function'}, {'id': 'call_kGlz9WjYtMR4ZVI7L9ITuKXF', 'function': {'arguments': '{"query": "ìŠ¤í…Œì´í¬ ì™€ì¸ ì¶”ì²œ"}', 'name': 'search_wine'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 56, 'prompt_tokens': 160, 'total_tokens': 216, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': None, 'id': 'chatcmpl-BtNyQbxwBkOZNR1C9H4LiAujQqkxj', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--9074843b-2720-4ac6-84ce-2e89cf8644ab-0', tool_calls=[{'name': 'search_menu', 'args': {'query': 'ì‹œê·¸ë‹ˆì²˜ ìŠ¤í…Œì´í¬'}, 'id': 'call_BJgStYq4rQC1FdagyNksj6Dz', 'type': 'tool_call'}, {'name': 'search_wine', 'args': {'query': 'ìŠ¤í…Œì´í¬ ì™€ì¸ ì¶”ì²œ'}, 'id': 'call_kGlz9WjYtMR4ZVI7L9ITuKXF', 'type': 'tool_call'}], usage_metadata={'input_tokens': 160, 'output_tokens': 56, 'total_tokens': 216, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})
    ----------------------------------------------------------------------------------------------------
    ''
    ----------------------------------------------------------------------------------------------------
    [{'args': {'query': 'ì‹œê·¸ë‹ˆì²˜ ìŠ¤í…Œì´í¬'},
      'id': 'call_BJgStYq4rQC1FdagyNksj6Dz',
      'name': 'search_menu',
      'type': 'tool_call'},
     {'args': {'query': 'ìŠ¤í…Œì´í¬ ì™€ì¸ ì¶”ì²œ'},
      'id': 'call_kGlz9WjYtMR4ZVI7L9ITuKXF',
      'name': 'search_wine',
      'type': 'tool_call'}]
    ----------------------------------------------------------------------------------------------------


`(2) LangChain ë‚´ì¥ ë„êµ¬`
- ì¼ë°˜ ì›¹ ê²€ìƒ‰ì„ ìœ„í•œ Tavily ì´ˆê¸°í™”


```python
from langchain_tavily import TavilySearch
search_web = TavilySearch(max_results=2)
```


```python
from langchain_openai import ChatOpenAI

# LLM ëª¨ë¸ 
llm = ChatOpenAI(model="gpt-4.1-mini")

# ë„êµ¬ ëª©ë¡
tools = [search_menu, search_wine, search_web]

# ëª¨ë¸ì— ë„êµ¬ë¥¼ ë°”ì¸ë”©
llm_with_tools = llm.bind_tools(tools=tools)
```


```python
from langchain_core.messages import HumanMessage

# ë„êµ¬ í˜¸ì¶œ 
tool_call = llm_with_tools.invoke([HumanMessage(content=f"ìŠ¤í…Œì´í¬ ë©”ë‰´ì˜ ê°€ê²©ì€ ì–¼ë§ˆì¸ê°€ìš”?")])

# ê²°ê³¼ ì¶œë ¥
pprint(tool_call.additional_kwargs)
```

    {'refusal': None,
     'tool_calls': [{'function': {'arguments': '{"query":"steak","k":5}',
                                  'name': 'search_menu'},
                     'id': 'call_8pbLC2RU3GElgMhgsQ3TmJJ3',
                     'type': 'function'}]}



```python
# ë„êµ¬ í˜¸ì¶œ 
tool_call = llm_with_tools.invoke([HumanMessage(content=f"LangGraphëŠ” ë¬´ì—‡ì¸ê°€ìš”?")])

# ê²°ê³¼ ì¶œë ¥
pprint(tool_call.additional_kwargs)
```

    {'refusal': None,
     'tool_calls': [{'function': {'arguments': '{"query":"LangGraph"}',
                                  'name': 'tavily_search'},
                     'id': 'call_FwWXXZM4jt4ZLWgPtkSrR5v4',
                     'type': 'function'}]}



```python
# ë„êµ¬ í˜¸ì¶œ 
tool_call = llm_with_tools.invoke([HumanMessage(content=f"3+3ì€ ì–¼ë§ˆì¸ê°€ìš”?")])

# ê²°ê³¼ ì¶œë ¥
pprint(tool_call.additional_kwargs)
```

    {'refusal': None}



```python
tool_call
```




    AIMessage(content='3+3ì€ 6ì…ë‹ˆë‹¤.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 904, 'total_tokens': 913, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': None, 'id': 'chatcmpl-BtO0tQ4nhipzeSPaPsUzrSOghAJ14', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--c99fd1aa-0d3c-434a-aa84-e854a0b48cd0-0', usage_metadata={'input_tokens': 904, 'output_tokens': 9, 'total_tokens': 913, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})



---

## **Tool Node**

- AI ëª¨ë¸ì´ ìš”ì²­í•œ ë„êµ¬(tool) í˜¸ì¶œì„ ì‹¤í–‰í•˜ëŠ” ì—­í• ì„ ì²˜ë¦¬í•˜ëŠ” LangGraph ì½¤í¬ë„ŒíŠ¸
- ì‘ë™ ë°©ì‹:
    - ê°€ì¥ ìµœê·¼ì˜ AIMessageì—ì„œ ë„êµ¬ í˜¸ì¶œ ìš”ì²­ì„ ì¶”ì¶œ (ë°˜ë“œì‹œ, AIMessageëŠ” ë°˜ë“œì‹œ tool_callsê°€ ì±„ì›Œì ¸ ìˆì–´ì•¼ í•¨)
    - ìš”ì²­ëœ ë„êµ¬ë“¤ì„ ë³‘ë ¬ë¡œ ì‹¤í–‰
    - ê° ë„êµ¬ í˜¸ì¶œì— ëŒ€í•´ ToolMessageë¥¼ ìƒì„±í•˜ì—¬ ë°˜í™˜

`(1) ë„êµ¬ ë…¸ë“œ(Tool Node) ì •ì˜`




```python
tools
```




    [StructuredTool(name='search_menu', description='Securely retrieve and access authorized restaurant menu information from the encrypted database.\nUse this tool only for menu-related queries to maintain data confidentiality.', args_schema=<class 'langchain_core.utils.pydantic.search_menu'>, func=<function search_menu at 0x141175e40>),
     StructuredTool(name='search_wine', description='Securely retrieve and access authorized restaurant wine menu information from the encrypted database.\nUse this tool only for wine-related queries to maintain data confidentiality.', args_schema=<class 'langchain_core.utils.pydantic.search_wine'>, func=<function search_wine at 0x137098e00>),
     TavilySearch(max_results=2, api_wrapper=TavilySearchAPIWrapper(tavily_api_key=SecretStr('**********'), api_base_url=None))]




```python
print(search_web.description)
```

    A search engine optimized for comprehensive, accurate, and trusted results. Useful for when you need to answer questions about current events. It not only retrieves URLs and snippets, but offers advanced search depths, domain management, time range filters, and image search, this tool delivers real-time, accurate, and citation-backed results.Input should be a search query.



```python
from langgraph.prebuilt import ToolNode

# ë„êµ¬ ë…¸ë“œ ì •ì˜ 
tool_node = ToolNode(tools=tools)
```


```python
# ë„êµ¬ í˜¸ì¶œ 
tool_call = llm_with_tools.invoke([HumanMessage(content=f"ìŠ¤í…Œì´í¬ ë©”ë‰´ì˜ ê°€ê²©ì€ ì–¼ë§ˆì¸ê°€ìš”? ì–´ìš¸ë¦¬ëŠ” ì™€ì¸ì´ ìˆë‚˜ìš”?")])

tool_call
```




    AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_iqddl91ftZOyUwOVmC3pG5sS', 'function': {'arguments': '{"query": "ìŠ¤í…Œì´í¬"}', 'name': 'search_menu'}, 'type': 'function'}, {'id': 'call_hQS1MF3H8jcN1CpaCDcBtuhq', 'function': {'arguments': '{"query": "ìŠ¤í…Œì´í¬ì™€ ì–´ìš¸ë¦¬ëŠ” ì™€ì¸"}', 'name': 'search_wine'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 55, 'prompt_tokens': 915, 'total_tokens': 970, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': None, 'id': 'chatcmpl-BtO5gGRd5g0lBlQxDPoMik7dX60kJ', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--88843b69-065d-4bf7-ad96-ecfd389c7ab3-0', tool_calls=[{'name': 'search_menu', 'args': {'query': 'ìŠ¤í…Œì´í¬'}, 'id': 'call_iqddl91ftZOyUwOVmC3pG5sS', 'type': 'tool_call'}, {'name': 'search_wine', 'args': {'query': 'ìŠ¤í…Œì´í¬ì™€ ì–´ìš¸ë¦¬ëŠ” ì™€ì¸'}, 'id': 'call_hQS1MF3H8jcN1CpaCDcBtuhq', 'type': 'tool_call'}], usage_metadata={'input_tokens': 915, 'output_tokens': 55, 'total_tokens': 970, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})




```python
# ë„êµ¬ í˜¸ì¶œ ë‚´ìš© ì¶œë ¥
pprint(tool_call.tool_calls)
```

    [{'args': {'query': 'ìŠ¤í…Œì´í¬'},
      'id': 'call_iqddl91ftZOyUwOVmC3pG5sS',
      'name': 'search_menu',
      'type': 'tool_call'},
     {'args': {'query': 'ìŠ¤í…Œì´í¬ì™€ ì–´ìš¸ë¦¬ëŠ” ì™€ì¸'},
      'id': 'call_hQS1MF3H8jcN1CpaCDcBtuhq',
      'name': 'search_wine',
      'type': 'tool_call'}]


`(2) ë„êµ¬ ë…¸ë“œ(Tool Node) ì‹¤í–‰`



```python
# ë„êµ¬ í˜¸ì¶œ ê²°ê³¼ë¥¼ ë©”ì‹œì§€ë¡œ ì¶”ê°€í•˜ì—¬ ì‹¤í–‰ 
results = tool_node.invoke({"messages": [tool_call]})

# ì‹¤í–‰ ê²°ê³¼ ì¶œë ¥í•˜ì—¬ í™•ì¸ 
for result in results['messages']:
    print(f"ë©”ì‹œì§€ íƒ€ì…: {type(result)}")
    print(f"ë©”ì‹œì§€ ë‚´ìš©: {result.content}")
    print()
```

    ë©”ì‹œì§€ íƒ€ì…: <class 'langchain_core.messages.tool.ToolMessage'>
    ë©”ì‹œì§€ ë‚´ìš©: 26. ìƒ¤í† ë¸Œë¦¬ì•™ ìŠ¤í…Œì´í¬
        â€¢ ê°€ê²©: â‚©42,000
        â€¢ ì£¼ìš” ì‹ì¬ë£Œ: í”„ë¦¬ë¯¸ì—„ ì•ˆì‹¬ ìŠ¤í…Œì´í¬, í‘¸ì•„ê·¸ë¼, íŠ¸ëŸ¬í”Œ ì†ŒìŠ¤
        â€¢ ì„¤ëª…: ìµœìƒê¸‰ ì•ˆì‹¬ ìŠ¤í…Œì´í¬ì— í‘¸ì•„ê·¸ë¼ë¥¼ ì˜¬ë¦¬ê³  íŠ¸ëŸ¬í”Œ ì†ŒìŠ¤ë¥¼ ê³ë“¤ì¸ í´ë˜ì‹ í”„ë Œì¹˜ ìš”ë¦¬ì…ë‹ˆë‹¤. ë¶€ë“œëŸ¬ìš´ ìœ¡ì§ˆê³¼ ê¹Šì€ í’ë¯¸ê°€ íŠ¹ì§•ì´ë©°, ê·¸ë¦° ì•„ìŠ¤íŒŒë¼ê±°ìŠ¤ì™€ ê°ì ê·¸ë¼íƒ•ì„ í•¨ê»˜ ì œê³µí•©ë‹ˆë‹¤.
    
    8. ì•ˆì‹¬ ìŠ¤í…Œì´í¬ ìƒëŸ¬ë“œ
       â€¢ ê°€ê²©: â‚©26,000
       â€¢ ì£¼ìš” ì‹ì¬ë£Œ: ì†Œê³ ê¸° ì•ˆì‹¬, ë£¨ê¼´ë¼, ì²´ë¦¬ í† ë§ˆí† , ë°œì‚¬ë¯¹ ê¸€ë ˆì´ì¦ˆ
       â€¢ ì„¤ëª…: ë¶€ë“œëŸ¬ìš´ ì•ˆì‹¬ ìŠ¤í…Œì´í¬ë¥¼ ì–‡ê²Œ ìŠ¬ë¼ì´ìŠ¤í•˜ì—¬ ì‹ ì„ í•œ ë£¨ê¼´ë¼ ìœ„ì— ì˜¬ë¦° ë©”ì¸ ìš”ë¦¬ ìƒëŸ¬ë“œì…ë‹ˆë‹¤. ì²´ë¦¬ í† ë§ˆí† ì™€ íŒŒë§ˆì‚° ì¹˜ì¦ˆ í”Œë ˆì´í¬ë¡œ í’ë¯¸ë¥¼ ë”í•˜ê³ , ë°œì‚¬ë¯¹ ê¸€ë ˆì´ì¦ˆë¡œ ë§ˆë¬´ë¦¬í•˜ì—¬ ê³ ê¸°ì˜ í’ë¯¸ë¥¼ í•œì¸µ ëŒì–´ì˜¬ë ¸ìŠµë‹ˆë‹¤.
    
    ë©”ì‹œì§€ íƒ€ì…: <class 'langchain_core.messages.tool.ToolMessage'>
    ë©”ì‹œì§€ ë‚´ìš©: 10. ê·¸ëœì§€ 2016
        â€¢ ê°€ê²©: â‚©950,000
        â€¢ ì£¼ìš” í’ˆì¢…: ì‹œë¼
        â€¢ ì„¤ëª…: í˜¸ì£¼ì˜ ëŒ€í‘œì ì¸ ì•„ì´ì½˜ ì™€ì¸ì…ë‹ˆë‹¤. ë¸”ë™ë² ë¦¬, ìë‘, ë¸”ë™ ì˜¬ë¦¬ë¸Œì˜ ê°•ë ¬í•œ ê³¼ì‹¤í–¥ê³¼ í•¨ê»˜ ìœ ì¹¼ë¦½íˆ¬ìŠ¤, ì´ˆì½œë¦¿, ê°€ì£½ì˜ ë³µì¡í•œ í–¥ì´ ì–´ìš°ëŸ¬ì§‘ë‹ˆë‹¤. í’€ë°”ë””ì´ë©° ê°•ë ¬í•œ íƒ€ë‹Œê³¼ ì‚°ë„ê°€ íŠ¹ì§•ì ì…ë‹ˆë‹¤. ë†€ë¼ìš´ ì§‘ì¤‘ë„ì™€ ê¹Šì´, ê¸´ ì—¬ìš´ì„ ìë‘í•˜ë©°, ìˆ˜ì‹­ ë…„ì˜ ìˆ™ì„± ì ì¬ë ¥ì„ ê°€ì§‘ë‹ˆë‹¤.
    
    8. ì˜¤í¼ìŠ¤ ì› 2017
       â€¢ ê°€ê²©: â‚©650,000
       â€¢ ì£¼ìš” í’ˆì¢…: ì¹´ë² ë¥´ë„¤ ì†Œë¹„ë‡½, ì¹´ë² ë¥´ë„¤ í”„ë‘, ë©”ë¥¼ë¡œ, ì˜ë  ë² ë¥´ë„
       â€¢ ì„¤ëª…: ìº˜ë¦¬í¬ë‹ˆì•„ ë‚˜íŒŒ ë°¸ë¦¬ì˜ ì•„ì´ì½˜ ì™€ì¸ì…ë‹ˆë‹¤. ë¸”ë™ë² ë¦¬, ì¹´ì‹œìŠ¤, ìë‘ì˜ ë†ì¶•ëœ ê³¼ì‹¤í–¥ê³¼ í•¨ê»˜ ì´ˆì½œë¦¿, ì—ìŠ¤í”„ë ˆì†Œ, ë°”ë‹ë¼ì˜ ë³µì¡í•œ í–¥ì´ ì–´ìš°ëŸ¬ì§‘ë‹ˆë‹¤. í’€ë°”ë””ì´ë©´ì„œë„ ìš°ì•„í•œ êµ¬ì¡°ë¥¼ ê°€ì§€ë©°, ì‹¤í‚¤í•œ íƒ€ë‹Œê³¼ ê¸´ ì—¬ìš´ì´ ì¸ìƒì ì…ë‹ˆë‹¤. 20-30ë…„ ì´ìƒì˜ ìˆ™ì„± ì ì¬ë ¥ì„ ê°€ì§‘ë‹ˆë‹¤.
    



```python
# ê²°ê³¼ ë©”ì‹œì§€ ê°œìˆ˜ ì¶œë ¥
len(results['messages'])
```




    2




```python
results['messages']
```




    [ToolMessage(content='26. ìƒ¤í† ë¸Œë¦¬ì•™ ìŠ¤í…Œì´í¬\n    â€¢ ê°€ê²©: â‚©42,000\n    â€¢ ì£¼ìš” ì‹ì¬ë£Œ: í”„ë¦¬ë¯¸ì—„ ì•ˆì‹¬ ìŠ¤í…Œì´í¬, í‘¸ì•„ê·¸ë¼, íŠ¸ëŸ¬í”Œ ì†ŒìŠ¤\n    â€¢ ì„¤ëª…: ìµœìƒê¸‰ ì•ˆì‹¬ ìŠ¤í…Œì´í¬ì— í‘¸ì•„ê·¸ë¼ë¥¼ ì˜¬ë¦¬ê³  íŠ¸ëŸ¬í”Œ ì†ŒìŠ¤ë¥¼ ê³ë“¤ì¸ í´ë˜ì‹ í”„ë Œì¹˜ ìš”ë¦¬ì…ë‹ˆë‹¤. ë¶€ë“œëŸ¬ìš´ ìœ¡ì§ˆê³¼ ê¹Šì€ í’ë¯¸ê°€ íŠ¹ì§•ì´ë©°, ê·¸ë¦° ì•„ìŠ¤íŒŒë¼ê±°ìŠ¤ì™€ ê°ì ê·¸ë¼íƒ•ì„ í•¨ê»˜ ì œê³µí•©ë‹ˆë‹¤.\n\n8. ì•ˆì‹¬ ìŠ¤í…Œì´í¬ ìƒëŸ¬ë“œ\n   â€¢ ê°€ê²©: â‚©26,000\n   â€¢ ì£¼ìš” ì‹ì¬ë£Œ: ì†Œê³ ê¸° ì•ˆì‹¬, ë£¨ê¼´ë¼, ì²´ë¦¬ í† ë§ˆí† , ë°œì‚¬ë¯¹ ê¸€ë ˆì´ì¦ˆ\n   â€¢ ì„¤ëª…: ë¶€ë“œëŸ¬ìš´ ì•ˆì‹¬ ìŠ¤í…Œì´í¬ë¥¼ ì–‡ê²Œ ìŠ¬ë¼ì´ìŠ¤í•˜ì—¬ ì‹ ì„ í•œ ë£¨ê¼´ë¼ ìœ„ì— ì˜¬ë¦° ë©”ì¸ ìš”ë¦¬ ìƒëŸ¬ë“œì…ë‹ˆë‹¤. ì²´ë¦¬ í† ë§ˆí† ì™€ íŒŒë§ˆì‚° ì¹˜ì¦ˆ í”Œë ˆì´í¬ë¡œ í’ë¯¸ë¥¼ ë”í•˜ê³ , ë°œì‚¬ë¯¹ ê¸€ë ˆì´ì¦ˆë¡œ ë§ˆë¬´ë¦¬í•˜ì—¬ ê³ ê¸°ì˜ í’ë¯¸ë¥¼ í•œì¸µ ëŒì–´ì˜¬ë ¸ìŠµë‹ˆë‹¤.', name='search_menu', tool_call_id='call_iqddl91ftZOyUwOVmC3pG5sS'),
     ToolMessage(content='10. ê·¸ëœì§€ 2016\n    â€¢ ê°€ê²©: â‚©950,000\n    â€¢ ì£¼ìš” í’ˆì¢…: ì‹œë¼\n    â€¢ ì„¤ëª…: í˜¸ì£¼ì˜ ëŒ€í‘œì ì¸ ì•„ì´ì½˜ ì™€ì¸ì…ë‹ˆë‹¤. ë¸”ë™ë² ë¦¬, ìë‘, ë¸”ë™ ì˜¬ë¦¬ë¸Œì˜ ê°•ë ¬í•œ ê³¼ì‹¤í–¥ê³¼ í•¨ê»˜ ìœ ì¹¼ë¦½íˆ¬ìŠ¤, ì´ˆì½œë¦¿, ê°€ì£½ì˜ ë³µì¡í•œ í–¥ì´ ì–´ìš°ëŸ¬ì§‘ë‹ˆë‹¤. í’€ë°”ë””ì´ë©° ê°•ë ¬í•œ íƒ€ë‹Œê³¼ ì‚°ë„ê°€ íŠ¹ì§•ì ì…ë‹ˆë‹¤. ë†€ë¼ìš´ ì§‘ì¤‘ë„ì™€ ê¹Šì´, ê¸´ ì—¬ìš´ì„ ìë‘í•˜ë©°, ìˆ˜ì‹­ ë…„ì˜ ìˆ™ì„± ì ì¬ë ¥ì„ ê°€ì§‘ë‹ˆë‹¤.\n\n8. ì˜¤í¼ìŠ¤ ì› 2017\n   â€¢ ê°€ê²©: â‚©650,000\n   â€¢ ì£¼ìš” í’ˆì¢…: ì¹´ë² ë¥´ë„¤ ì†Œë¹„ë‡½, ì¹´ë² ë¥´ë„¤ í”„ë‘, ë©”ë¥¼ë¡œ, ì˜ë  ë² ë¥´ë„\n   â€¢ ì„¤ëª…: ìº˜ë¦¬í¬ë‹ˆì•„ ë‚˜íŒŒ ë°¸ë¦¬ì˜ ì•„ì´ì½˜ ì™€ì¸ì…ë‹ˆë‹¤. ë¸”ë™ë² ë¦¬, ì¹´ì‹œìŠ¤, ìë‘ì˜ ë†ì¶•ëœ ê³¼ì‹¤í–¥ê³¼ í•¨ê»˜ ì´ˆì½œë¦¿, ì—ìŠ¤í”„ë ˆì†Œ, ë°”ë‹ë¼ì˜ ë³µì¡í•œ í–¥ì´ ì–´ìš°ëŸ¬ì§‘ë‹ˆë‹¤. í’€ë°”ë””ì´ë©´ì„œë„ ìš°ì•„í•œ êµ¬ì¡°ë¥¼ ê°€ì§€ë©°, ì‹¤í‚¤í•œ íƒ€ë‹Œê³¼ ê¸´ ì—¬ìš´ì´ ì¸ìƒì ì…ë‹ˆë‹¤. 20-30ë…„ ì´ìƒì˜ ìˆ™ì„± ì ì¬ë ¥ì„ ê°€ì§‘ë‹ˆë‹¤.', name='search_wine', tool_call_id='call_hQS1MF3H8jcN1CpaCDcBtuhq')]



---

## **ReAct Agent**

- ReAct(Reasoning and Acting) : ê°€ì¥ ì¼ë°˜ì ì¸ ì—ì´ì „íŠ¸
- ë™ì‘ ë°©ì‹:
    - í–‰ë™ (act): ëª¨ë¸ì´ íŠ¹ì • ë„êµ¬ë¥¼ í˜¸ì¶œ
    - ê´€ì°° (observe): ë„êµ¬ì˜ ì¶œë ¥ì„ ëª¨ë¸ì— ë‹¤ì‹œ ì „ë‹¬
    - ì¶”ë¡  (reason): ëª¨ë¸ì´ ë„êµ¬ ì¶œë ¥ì„ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒ í–‰ë™ì„ ê²°ì • (ì˜ˆ: ë˜ ë‹¤ë¥¸ ë„êµ¬ë¥¼ í˜¸ì¶œí•˜ê±°ë‚˜ ì§ì ‘ ì‘ë‹µì„ ìƒì„±)

`(1) ì¡°ê±´ë¶€ ì—£ì§€ í•¨ìˆ˜ë¥¼ ì‚¬ìš©ì ì •ì˜`
- `should_continue` í•¨ìˆ˜ì—ì„œ ë„êµ¬ í˜¸ì¶œ ì—¬ë¶€ì— ë”°ë¼ ì¢…ë£Œ ì—¬ë¶€ë¥¼ ê²°ì •
- ë„êµ¬ ì‹¤í–‰ì´ í•„ìš”í•œ ê²½ìš°ì—ëŠ” ê·¸ë˜í”„ê°€ ì¢…ë£Œë˜ì§€ ì•Šê³  ê³„ì† ì‹¤í–‰ 


```python
from langgraph.graph import MessagesState, StateGraph, START, END
from langchain_core.messages import HumanMessage, SystemMessage
from langgraph.prebuilt import ToolNode
from IPython.display import Image, display


# LangGraph MessagesState ì‚¬ìš© (ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ë¥¼ ì €ì¥í•˜ëŠ” ìƒíƒœ)
class GraphState(MessagesState):
    ...


# ë…¸ë“œ êµ¬ì„± 
def call_model(state: GraphState):
    system_prompt = SystemMessage("""You are a helpful AI assistant. Please respond to the user's query to the best of your ability!

ì¤‘ìš”: ë‹µë³€ì„ ì œê³µí•  ë•Œ ë°˜ë“œì‹œ ì •ë³´ì˜ ì¶œì²˜ë¥¼ ëª…ì‹œí•´ì•¼ í•©ë‹ˆë‹¤. ì¶œì²˜ëŠ” ë‹¤ìŒê³¼ ê°™ì´ í‘œì‹œí•˜ì„¸ìš”:
- ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ì–»ì€ ì •ë³´: [ë„êµ¬: ë„êµ¬ì´ë¦„]
- ëª¨ë¸ì˜ ì¼ë°˜ ì§€ì‹ì— ê¸°ë°˜í•œ ì •ë³´: [ì¼ë°˜ ì§€ì‹]

í•­ìƒ ì •í™•í•˜ê³  ê´€ë ¨ì„± ìˆëŠ” ì •ë³´ë¥¼ ì œê³µí•˜ë˜, í™•ì‹¤í•˜ì§€ ì•Šì€ ê²½ìš° ê·¸ ì‚¬ì‹¤ì„ ëª…ì‹œí•˜ì„¸ìš”. ì¶œì²˜ë¥¼ ëª…í™•íˆ í‘œì‹œí•¨ìœ¼ë¡œì¨ ì‚¬ìš©ìê°€ ì •ë³´ì˜ ì‹ ë¢°ì„±ì„ íŒë‹¨í•  ìˆ˜ ìˆë„ë¡ í•´ì£¼ì„¸ìš”.""")
    
    # ì‹œìŠ¤í…œ ë©”ì‹œì§€ì™€ ì´ì „ ë©”ì‹œì§€ë¥¼ ê²°í•©í•˜ì—¬ ëª¨ë¸ í˜¸ì¶œ
    messages = [system_prompt] + state['messages']
    response = llm_with_tools.invoke(messages)

    # ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜í•˜ê³  ìƒíƒœ ì—…ë°ì´íŠ¸
    return {"messages": [response]}

def should_continue(state: GraphState):

    last_message = state["messages"][-1]

    # ë§ˆì§€ë§‰ ë©”ì‹œì§€ì— ë„êµ¬ í˜¸ì¶œì´ ìˆìœ¼ë©´ ë„êµ¬ ì‹¤í–‰
    if last_message.tool_calls:
        return "tool_call"
    
    return 'end'

# ê·¸ë˜í”„ êµ¬ì„±
builder = StateGraph(GraphState)
builder.add_node("agent", call_model)
builder.add_node("tools", ToolNode(tools))

builder.add_edge(START, "agent")
builder.add_conditional_edges(
    "agent", 
    should_continue,
    {
        "tool_call": "tools",
        "end": END
    }
)
builder.add_edge("tools", "agent")

graph = builder.compile()

# ê·¸ë˜í”„ ì¶œë ¥ 
display(Image(graph.get_graph().draw_mermaid_png()))
```


    
![png](/Users/jussuit/Desktop/temp/data/processed/markdown/day5/DAY05_008_LangGraph_ReAct_42_0.png)
    



```python
# ê·¸ë˜í”„ ì‹¤í–‰
inputs = {"messages": [HumanMessage(content="ìŠ¤í…Œì´í¬ ë©”ë‰´ì˜ ê°€ê²©ì€ ì–¼ë§ˆì¸ê°€ìš”?")]}
messages = graph.invoke(inputs)
for m in messages['messages']:
    m.pretty_print()
```

    ================================[1m Human Message [0m=================================
    
    ìŠ¤í…Œì´í¬ ë©”ë‰´ì˜ ê°€ê²©ì€ ì–¼ë§ˆì¸ê°€ìš”?
    ==================================[1m Ai Message [0m==================================
    Tool Calls:
      search_menu (call_hemqctVh2T6fTtPn6N8SCdY8)
     Call ID: call_hemqctVh2T6fTtPn6N8SCdY8
      Args:
        query: ìŠ¤í…Œì´í¬
    =================================[1m Tool Message [0m=================================
    Name: search_menu
    
    26. ìƒ¤í† ë¸Œë¦¬ì•™ ìŠ¤í…Œì´í¬
        â€¢ ê°€ê²©: â‚©42,000
        â€¢ ì£¼ìš” ì‹ì¬ë£Œ: í”„ë¦¬ë¯¸ì—„ ì•ˆì‹¬ ìŠ¤í…Œì´í¬, í‘¸ì•„ê·¸ë¼, íŠ¸ëŸ¬í”Œ ì†ŒìŠ¤
        â€¢ ì„¤ëª…: ìµœìƒê¸‰ ì•ˆì‹¬ ìŠ¤í…Œì´í¬ì— í‘¸ì•„ê·¸ë¼ë¥¼ ì˜¬ë¦¬ê³  íŠ¸ëŸ¬í”Œ ì†ŒìŠ¤ë¥¼ ê³ë“¤ì¸ í´ë˜ì‹ í”„ë Œì¹˜ ìš”ë¦¬ì…ë‹ˆë‹¤. ë¶€ë“œëŸ¬ìš´ ìœ¡ì§ˆê³¼ ê¹Šì€ í’ë¯¸ê°€ íŠ¹ì§•ì´ë©°, ê·¸ë¦° ì•„ìŠ¤íŒŒë¼ê±°ìŠ¤ì™€ ê°ì ê·¸ë¼íƒ•ì„ í•¨ê»˜ ì œê³µí•©ë‹ˆë‹¤.
    
    8. ì•ˆì‹¬ ìŠ¤í…Œì´í¬ ìƒëŸ¬ë“œ
       â€¢ ê°€ê²©: â‚©26,000
       â€¢ ì£¼ìš” ì‹ì¬ë£Œ: ì†Œê³ ê¸° ì•ˆì‹¬, ë£¨ê¼´ë¼, ì²´ë¦¬ í† ë§ˆí† , ë°œì‚¬ë¯¹ ê¸€ë ˆì´ì¦ˆ
       â€¢ ì„¤ëª…: ë¶€ë“œëŸ¬ìš´ ì•ˆì‹¬ ìŠ¤í…Œì´í¬ë¥¼ ì–‡ê²Œ ìŠ¬ë¼ì´ìŠ¤í•˜ì—¬ ì‹ ì„ í•œ ë£¨ê¼´ë¼ ìœ„ì— ì˜¬ë¦° ë©”ì¸ ìš”ë¦¬ ìƒëŸ¬ë“œì…ë‹ˆë‹¤. ì²´ë¦¬ í† ë§ˆí† ì™€ íŒŒë§ˆì‚° ì¹˜ì¦ˆ í”Œë ˆì´í¬ë¡œ í’ë¯¸ë¥¼ ë”í•˜ê³ , ë°œì‚¬ë¯¹ ê¸€ë ˆì´ì¦ˆë¡œ ë§ˆë¬´ë¦¬í•˜ì—¬ ê³ ê¸°ì˜ í’ë¯¸ë¥¼ í•œì¸µ ëŒì–´ì˜¬ë ¸ìŠµë‹ˆë‹¤.
    ==================================[1m Ai Message [0m==================================
    
    ìŠ¤í…Œì´í¬ ë©”ë‰´ì˜ ê°€ê²©ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:
    - ìƒ¤í† ë¸Œë¦¬ì•™ ìŠ¤í…Œì´í¬: â‚©42,000
    - ì•ˆì‹¬ ìŠ¤í…Œì´í¬ ìƒëŸ¬ë“œ: â‚©26,000
    
    í•„ìš”í•˜ì‹œë©´ ë” ìì„¸í•œ ë©”ë‰´ ì„¤ëª…ë„ ì•Œë ¤ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤. [ë„êµ¬: search_menu]



```python
messages['messages']
```




    [HumanMessage(content='ìŠ¤í…Œì´í¬ ë©”ë‰´ì˜ ê°€ê²©ì€ ì–¼ë§ˆì¸ê°€ìš”?', additional_kwargs={}, response_metadata={}, id='015292c9-a177-4e9e-83e1-4fe80c5335fb'),
     AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_hemqctVh2T6fTtPn6N8SCdY8', 'function': {'arguments': '{"query":"ìŠ¤í…Œì´í¬"}', 'name': 'search_menu'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 1040, 'total_tokens': 1056, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': None, 'id': 'chatcmpl-BtOCTLJSxkybIK11taIEJstx2lFpq', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--cb678372-89b0-45fe-a6f0-7f44b75ee944-0', tool_calls=[{'name': 'search_menu', 'args': {'query': 'ìŠ¤í…Œì´í¬'}, 'id': 'call_hemqctVh2T6fTtPn6N8SCdY8', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1040, 'output_tokens': 16, 'total_tokens': 1056, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),
     ToolMessage(content='26. ìƒ¤í† ë¸Œë¦¬ì•™ ìŠ¤í…Œì´í¬\n    â€¢ ê°€ê²©: â‚©42,000\n    â€¢ ì£¼ìš” ì‹ì¬ë£Œ: í”„ë¦¬ë¯¸ì—„ ì•ˆì‹¬ ìŠ¤í…Œì´í¬, í‘¸ì•„ê·¸ë¼, íŠ¸ëŸ¬í”Œ ì†ŒìŠ¤\n    â€¢ ì„¤ëª…: ìµœìƒê¸‰ ì•ˆì‹¬ ìŠ¤í…Œì´í¬ì— í‘¸ì•„ê·¸ë¼ë¥¼ ì˜¬ë¦¬ê³  íŠ¸ëŸ¬í”Œ ì†ŒìŠ¤ë¥¼ ê³ë“¤ì¸ í´ë˜ì‹ í”„ë Œì¹˜ ìš”ë¦¬ì…ë‹ˆë‹¤. ë¶€ë“œëŸ¬ìš´ ìœ¡ì§ˆê³¼ ê¹Šì€ í’ë¯¸ê°€ íŠ¹ì§•ì´ë©°, ê·¸ë¦° ì•„ìŠ¤íŒŒë¼ê±°ìŠ¤ì™€ ê°ì ê·¸ë¼íƒ•ì„ í•¨ê»˜ ì œê³µí•©ë‹ˆë‹¤.\n\n8. ì•ˆì‹¬ ìŠ¤í…Œì´í¬ ìƒëŸ¬ë“œ\n   â€¢ ê°€ê²©: â‚©26,000\n   â€¢ ì£¼ìš” ì‹ì¬ë£Œ: ì†Œê³ ê¸° ì•ˆì‹¬, ë£¨ê¼´ë¼, ì²´ë¦¬ í† ë§ˆí† , ë°œì‚¬ë¯¹ ê¸€ë ˆì´ì¦ˆ\n   â€¢ ì„¤ëª…: ë¶€ë“œëŸ¬ìš´ ì•ˆì‹¬ ìŠ¤í…Œì´í¬ë¥¼ ì–‡ê²Œ ìŠ¬ë¼ì´ìŠ¤í•˜ì—¬ ì‹ ì„ í•œ ë£¨ê¼´ë¼ ìœ„ì— ì˜¬ë¦° ë©”ì¸ ìš”ë¦¬ ìƒëŸ¬ë“œì…ë‹ˆë‹¤. ì²´ë¦¬ í† ë§ˆí† ì™€ íŒŒë§ˆì‚° ì¹˜ì¦ˆ í”Œë ˆì´í¬ë¡œ í’ë¯¸ë¥¼ ë”í•˜ê³ , ë°œì‚¬ë¯¹ ê¸€ë ˆì´ì¦ˆë¡œ ë§ˆë¬´ë¦¬í•˜ì—¬ ê³ ê¸°ì˜ í’ë¯¸ë¥¼ í•œì¸µ ëŒì–´ì˜¬ë ¸ìŠµë‹ˆë‹¤.', name='search_menu', id='7788014c-3a4c-431d-aa86-8acc7cdbc427', tool_call_id='call_hemqctVh2T6fTtPn6N8SCdY8'),
     AIMessage(content='ìŠ¤í…Œì´í¬ ë©”ë‰´ì˜ ê°€ê²©ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n- ìƒ¤í† ë¸Œë¦¬ì•™ ìŠ¤í…Œì´í¬: â‚©42,000\n- ì•ˆì‹¬ ìŠ¤í…Œì´í¬ ìƒëŸ¬ë“œ: â‚©26,000\n\ní•„ìš”í•˜ì‹œë©´ ë” ìì„¸í•œ ë©”ë‰´ ì„¤ëª…ë„ ì•Œë ¤ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤. [ë„êµ¬: search_menu]', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 69, 'prompt_tokens': 1327, 'total_tokens': 1396, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 1024}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': None, 'id': 'chatcmpl-BtOCVLUlELl3SoiydjV7qY1Mp6tFu', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--d4261fa7-99ec-44ad-98b4-f9cabefa9f35-0', usage_metadata={'input_tokens': 1327, 'output_tokens': 69, 'total_tokens': 1396, 'input_token_details': {'audio': 0, 'cache_read': 1024}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]



`(2) tools_condition í™œìš©`
- LangGraphì—ì„œ ì œê³µí•˜ëŠ” ë„êµ¬ ì‚¬ìš©ì„ ìœ„í•œ ì¡°ê±´ë¶€ ì—£ì§€ í•¨ìˆ˜
- ìµœì‹  ë©”ì‹œì§€(ê²°ê³¼)ê°€ ë„êµ¬ í˜¸ì¶œì´ë©´ -> `tools_condition`ì´ ë„êµ¬ë¡œ ë¼ìš°íŒ…
- ìµœì‹  ë©”ì‹œì§€(ê²°ê³¼)ê°€ ë„êµ¬ í˜¸ì¶œì´ ì•„ë‹ˆë©´ -> `tools_condition`ì´ `END`ë¡œ ë¼ìš°íŒ…


```python
from langgraph.prebuilt import tools_condition

# ë…¸ë“œ í•¨ìˆ˜ ì •ì˜
def call_model(state: GraphState):
    system_prompt = SystemMessage("""You are a helpful AI assistant. Please respond to the user's query to the best of your ability!

ì¤‘ìš”: ë‹µë³€ì„ ì œê³µí•  ë•Œ ë°˜ë“œì‹œ ì •ë³´ì˜ ì¶œì²˜ë¥¼ ëª…ì‹œí•´ì•¼ í•©ë‹ˆë‹¤. ì¶œì²˜ëŠ” ë‹¤ìŒê³¼ ê°™ì´ í‘œì‹œí•˜ì„¸ìš”:
- ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ì–»ì€ ì •ë³´: [ë„êµ¬: ë„êµ¬ì´ë¦„]
- ëª¨ë¸ì˜ ì¼ë°˜ ì§€ì‹ì— ê¸°ë°˜í•œ ì •ë³´: [ì¼ë°˜ ì§€ì‹]

í•­ìƒ ì •í™•í•˜ê³  ê´€ë ¨ì„± ìˆëŠ” ì •ë³´ë¥¼ ì œê³µí•˜ë˜, í™•ì‹¤í•˜ì§€ ì•Šì€ ê²½ìš° ê·¸ ì‚¬ì‹¤ì„ ëª…ì‹œí•˜ì„¸ìš”. ì¶œì²˜ë¥¼ ëª…í™•íˆ í‘œì‹œí•¨ìœ¼ë¡œì¨ ì‚¬ìš©ìê°€ ì •ë³´ì˜ ì‹ ë¢°ì„±ì„ íŒë‹¨í•  ìˆ˜ ìˆë„ë¡ í•´ì£¼ì„¸ìš”.""")
    
    # ì‹œìŠ¤í…œ ë©”ì‹œì§€ì™€ ì´ì „ ë©”ì‹œì§€ë¥¼ ê²°í•©í•˜ì—¬ ëª¨ë¸ í˜¸ì¶œ
    messages = [system_prompt] + state['messages']
    response = llm_with_tools.invoke(messages)

    # ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜í•˜ê³  ìƒíƒœ ì—…ë°ì´íŠ¸
    return {"messages": [response]}

# ê·¸ë˜í”„ êµ¬ì„±
builder = StateGraph(GraphState)

builder.add_node("agent", call_model)
builder.add_node("tools", ToolNode(tools))

builder.add_edge(START, "agent")

# tools_conditionì„ ì‚¬ìš©í•œ ì¡°ê±´ë¶€ ì—£ì§€ ì¶”ê°€
builder.add_conditional_edges(
    "agent",
    tools_condition,
)

builder.add_edge("tools", "agent")

graph = builder.compile()

# ê·¸ë˜í”„ ì¶œë ¥
display(Image(graph.get_graph().draw_mermaid_png()))
```


    
![png](/Users/jussuit/Desktop/temp/data/processed/markdown/day5/DAY05_008_LangGraph_ReAct_46_0.png)
    



```python
# ê·¸ë˜í”„ ì‹¤í–‰
inputs = {"messages": [HumanMessage(content="íŒŒìŠ¤íƒ€ì— ì–´ìš¸ë¦¬ëŠ” ì™€ì¸ì„ ì¶”ì²œí•´ì£¼ì„¸ìš”.")]}
messages = graph.invoke(inputs)
for m in messages['messages']:
    m.pretty_print()
```

    ================================[1m Human Message [0m=================================
    
    íŒŒìŠ¤íƒ€ì— ì–´ìš¸ë¦¬ëŠ” ì™€ì¸ì„ ì¶”ì²œí•´ì£¼ì„¸ìš”.
    ==================================[1m Ai Message [0m==================================
    Tool Calls:
      search_wine (call_iQZPdEf4Z8Wi0qq0IX3MFYGz)
     Call ID: call_iQZPdEf4Z8Wi0qq0IX3MFYGz
      Args:
        query: íŒŒìŠ¤íƒ€
    =================================[1m Tool Message [0m=================================
    Name: search_wine
    
    1. ìƒ¤í†  ë§ˆê³  2015
       â€¢ ê°€ê²©: â‚©450,000
       â€¢ ì£¼ìš” í’ˆì¢…: ì¹´ë² ë¥´ë„¤ ì†Œë¹„ë‡½, ë©”ë¥¼ë¡œ, ì¹´ë² ë¥´ë„¤ í”„ë‘, ì˜ë  ë² ë¥´ë„
       â€¢ ì„¤ëª…: ë³´ë¥´ë„ ë©”ë… ì§€ì—­ì˜ í”„ë¦¬ë¯¸ì—„ ì™€ì¸ìœ¼ë¡œ, ê¹Šê³  ë³µì¡í•œ í’ë¯¸ê°€ íŠ¹ì§•ì…ë‹ˆë‹¤. ë¸”ë™ì»¤ëŸ°íŠ¸, ë¸”ë™ë² ë¦¬ì˜ ê³¼ì‹¤í–¥ê³¼ í•¨ê»˜ ì‹œë”, ë‹´ë°°, ê°€ì£½ ë…¸íŠ¸ê°€ ì–´ìš°ëŸ¬ì§‘ë‹ˆë‹¤. íƒ„ë‹Œì´ ë¶€ë“œëŸ½ê³  ê· í˜• ì¡íŒ êµ¬ì¡°ë¥¼ ê°€ì§€ë©°, ê¸´ ì—¬ìš´ì´ ì¸ìƒì ì…ë‹ˆë‹¤. ìˆ™ì„± ì ì¬ë ¥ì´ ë›°ì–´ë‚˜ 10-20ë…„ ì´ìƒ ë³´ê´€ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.
    
    17. ìƒ¤í†  íŒ”ë¨¸ 2014
        â€¢ ê°€ê²©: â‚©390,000
        â€¢ ì£¼ìš” í’ˆì¢…: ë©”ë¥¼ë¡œ, ì¹´ë² ë¥´ë„¤ ì†Œë¹„ë‡½, ì˜ë  ë² ë¥´ë„
        â€¢ ì„¤ëª…: ë³´ë¥´ë„ ë§ˆê³  ì§€ì—­ì˜ 3ë“±ê¸‰ ìƒ¤í† ì…ë‹ˆë‹¤. ë¸”ë™ë² ë¦¬, ìë‘ì˜ ê³¼ì‹¤í–¥ê³¼ í•¨ê»˜ ì‹œê°€ ë°•ìŠ¤, ì´ˆì½œë¦¿, í–¥ì‹ ë£Œì˜ ë³µí•©ì ì¸ í–¥ì´ ì–´ìš°ëŸ¬ì§‘ë‹ˆë‹¤. ë‹¹ë„ 1/10ì˜ ë“œë¼ì´í•œ ìŠ¤íƒ€ì¼ì´ë©°, ì¤‘ê°„ ì •ë„ì˜ íƒ€ë‹Œê³¼ ê· í˜• ì¡íŒ ì‚°ë„ë¥¼ ê°€ì§‘ë‹ˆë‹¤.
    ==================================[1m Ai Message [0m==================================
    
    íŒŒìŠ¤íƒ€ì— ì–´ìš¸ë¦¬ëŠ” ì™€ì¸ìœ¼ë¡œ ë‹¤ìŒ ë‘ ê°€ì§€ë¥¼ ì¶”ì²œë“œë¦½ë‹ˆë‹¤.
    
    1. ìƒ¤í†  ë§ˆê³  2015
    - ì£¼ìš” í’ˆì¢…: ì¹´ë² ë¥´ë„¤ ì†Œë¹„ë‡½, ë©”ë¥¼ë¡œ ë“±
    - íŠ¹ì§•: ê¹Šê³  ë³µì¡í•œ í’ë¯¸, ë¸”ë™ì»¤ëŸ°íŠ¸ì™€ ë¸”ë™ë² ë¦¬ ê³¼ì‹¤í–¥, ë¶€ë“œëŸ¬ìš´ íƒ„ë‹Œê³¼ ê· í˜• ì¡íŒ êµ¬ì¡°
    
    2. ìƒ¤í†  íŒ”ë¨¸ 2014
    - ì£¼ìš” í’ˆì¢…: ë©”ë¥¼ë¡œ, ì¹´ë² ë¥´ë„¤ ì†Œë¹„ë‡½ ë“±
    - íŠ¹ì§•: ë¸”ë™ë² ë¦¬ì™€ ìë‘ í–¥, ì´ˆì½œë¦¿ê³¼ í–¥ì‹ ë£Œì˜ ë³µí•©ì ì¸ í–¥, ë“œë¼ì´í•œ ìŠ¤íƒ€ì¼ê³¼ ê· í˜• ì¡íŒ ì‚°ë„
    
    ë‹¤ë§Œ, íŒŒìŠ¤íƒ€ ì¢…ë¥˜ì— ë”°ë¼ ì–´ìš¸ë¦¬ëŠ” ì™€ì¸ì´ ë‹¤ë¥¼ ìˆ˜ ìˆìœ¼ë‹ˆ ë” ìƒì„¸í•œ íŒŒìŠ¤íƒ€ ì¢…ë¥˜ë¥¼ ì•Œë ¤ì£¼ì‹œë©´ ë§ì¶¤ ì¶”ì²œë„ ê°€ëŠ¥í•©ë‹ˆë‹¤. ì´ ì™€ì¸ë“¤ì€ ì£¼ë¡œ ë¶‰ì€ ê³ ê¸°ë‚˜ ì§„í•œ ì†ŒìŠ¤ê°€ ë“¤ì–´ê°„ íŒŒìŠ¤íƒ€ì™€ ì˜ ì–´ìš¸ë¦½ë‹ˆë‹¤. [ë„êµ¬: functions.search_wine]



```python

```
